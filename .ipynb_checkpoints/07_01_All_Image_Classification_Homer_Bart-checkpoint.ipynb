{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "7znwBf0O6tpE"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import zipfile\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "dVfbaWDe8htY",
    "outputId": "998eef1f-4222-47d1-8f7f-51554c345742"
   },
   "outputs": [],
   "source": [
    "# path='/content/homer_bart_2.zip'\n",
    "\n",
    "# zip_obect=zipfile.ZipFile(file=path,mode='r')\n",
    "# zip_obect.extractall('./')\n",
    "# zip_obect.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = []\n",
    "histories = []\n",
    "\n",
    "# Function to evaluate a model and return metrics\n",
    "def evaluate_model(model, validation_generator):\n",
    "    # Evaluate the model on the validation data\n",
    "    val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    val_steps = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "    predictions = model.predict(validation_generator, steps=val_steps)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = validation_generator.classes\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(true_classes, predicted_classes, target_names=validation_generator.class_indices.keys(), output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': val_accuracy,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "\n",
    "# Function to plot validation loss and accuracy\n",
    "def plot_metrics(history, model_name):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['val_loss'], label=f'Validation Loss ({model_name})')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['val_accuracy'], label=f'Validation Accuracy ({model_name})')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix ({model_name})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHYWcwOTfIMP"
   },
   "source": [
    "#### Preprocessing on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "(64, 64, 3)\n",
      "{'bart': 0, 'homer': 1}\n",
      "{'bart': 0, 'homer': 1}\n",
      "{}\n",
      "(224, 224, 3)\n",
      "{'bart': 0, 'homer': 1}\n",
      "{'bart': 0, 'homer': 1}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your dataset\n",
    "dataset_path = 'homer_bart_1'\n",
    "\n",
    "# Create an ImageDataGenerator for training with data augmentation and validation split\n",
    "datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 20, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, validation_split = 0.2)\n",
    "\n",
    "# Load training data with augmentation\n",
    "train_generator = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Load training data with augmentation\n",
    "train_generator_224 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator_224 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Create a separate ImageDataGenerator for test data (only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Define the path to your test dataset\n",
    "test_dataset_path = 'test_dataset'\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(test_dataset_path, target_size = (64, 64), batch_size = 1, class_mode = 'binary')\n",
    "test_generator_244 = test_datagen.flow_from_directory(test_dataset_path, target_size = (224, 224), batch_size = 1, class_mode = 'binary')\n",
    "\n",
    "# Print class indices\n",
    "print(\"(64, 64, 3)\")\n",
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)\n",
    "\n",
    "print(\"(224, 224, 3)\")\n",
    "print(train_generator_224.class_indices)\n",
    "print(validation_generator_224.class_indices)\n",
    "print(test_generator_244.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSqnbI1VjU5J"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D Model (Checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EccXSMwHi4RI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 683,329\n",
      "Trainable params: 683,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model_check = Sequential([\n",
    "    layers.InputLayer(input_shape = (64, 64, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(1, activation = 'sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model_check.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG-9aj9RknrC",
    "outputId": "f638a7c7-3f2c-4e78-81d0-4fea757c475b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 188ms/step - loss: 0.7241 - accuracy: 0.4815 - val_loss: 0.6773 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6953 - accuracy: 0.5926 - val_loss: 0.6637 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.6719 - accuracy: 0.5926 - val_loss: 0.6592 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.6461 - accuracy: 0.5926 - val_loss: 0.6033 - val_accuracy: 0.6226\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.6002 - accuracy: 0.6944 - val_loss: 0.4840 - val_accuracy: 0.7736\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.5640 - accuracy: 0.7546 - val_loss: 0.5168 - val_accuracy: 0.7358\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.5540 - accuracy: 0.7176 - val_loss: 0.4929 - val_accuracy: 0.7736\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.5354 - accuracy: 0.7361 - val_loss: 0.5062 - val_accuracy: 0.7170\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5100 - accuracy: 0.7731 - val_loss: 0.4751 - val_accuracy: 0.7736\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.4585 - accuracy: 0.8102 - val_loss: 0.4212 - val_accuracy: 0.7736\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.4564 - accuracy: 0.7870 - val_loss: 0.4989 - val_accuracy: 0.7170\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.4932 - accuracy: 0.7407 - val_loss: 0.4687 - val_accuracy: 0.7736\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.4979 - accuracy: 0.7546 - val_loss: 0.4299 - val_accuracy: 0.7736\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.4725 - accuracy: 0.7639 - val_loss: 0.4688 - val_accuracy: 0.7547\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.4364 - accuracy: 0.8009 - val_loss: 0.4358 - val_accuracy: 0.8113\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.4087 - accuracy: 0.7778 - val_loss: 0.3967 - val_accuracy: 0.7736\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.3815 - accuracy: 0.8148 - val_loss: 0.3972 - val_accuracy: 0.8302\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.3302 - accuracy: 0.8287 - val_loss: 0.4448 - val_accuracy: 0.7736\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.3148 - accuracy: 0.8611 - val_loss: 0.4198 - val_accuracy: 0.8491\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.3561 - accuracy: 0.8380 - val_loss: 0.3943 - val_accuracy: 0.7925\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.3113 - accuracy: 0.8611 - val_loss: 0.4485 - val_accuracy: 0.7925\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.2545 - accuracy: 0.8843 - val_loss: 0.3995 - val_accuracy: 0.7925\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.2192 - accuracy: 0.9120 - val_loss: 0.4093 - val_accuracy: 0.7925\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.2783 - accuracy: 0.8981 - val_loss: 0.3993 - val_accuracy: 0.8113\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.2927 - accuracy: 0.8935 - val_loss: 0.3406 - val_accuracy: 0.8113\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.2297 - accuracy: 0.9074 - val_loss: 0.4243 - val_accuracy: 0.8302\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.3126 - accuracy: 0.8843 - val_loss: 0.3555 - val_accuracy: 0.8491\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.2200 - accuracy: 0.9213 - val_loss: 0.3183 - val_accuracy: 0.8679\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.2618 - accuracy: 0.8796 - val_loss: 0.3589 - val_accuracy: 0.7925\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.2510 - accuracy: 0.8796 - val_loss: 0.3985 - val_accuracy: 0.8491\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.2254 - accuracy: 0.8750 - val_loss: 0.3913 - val_accuracy: 0.8302\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.2082 - accuracy: 0.9120 - val_loss: 0.3512 - val_accuracy: 0.8113\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.1811 - accuracy: 0.9213 - val_loss: 0.3624 - val_accuracy: 0.8302\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.2328 - accuracy: 0.8935 - val_loss: 0.3354 - val_accuracy: 0.8113\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.2065 - accuracy: 0.9028 - val_loss: 0.4017 - val_accuracy: 0.8113\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.1856 - accuracy: 0.9259 - val_loss: 0.4419 - val_accuracy: 0.8302\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.1985 - accuracy: 0.9167 - val_loss: 0.3744 - val_accuracy: 0.8491\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.1793 - accuracy: 0.9213 - val_loss: 0.3741 - val_accuracy: 0.8491\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_check.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True)\n",
    "history_check = model_check.fit(train_generator, validation_data = validation_generator, epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(model_check)\n",
    "model_names.append(\"Conv2D Check\")\n",
    "histories.append(history_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from generators to numpy arrays\n",
    "\n",
    "def generator_to_numpy(generator):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for _ in range(len(generator)):\n",
    "        img_batch, label_batch = generator.next()\n",
    "        images.extend(img_batch)\n",
    "        labels.extend(label_batch)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation data as numpy arrays\n",
    "X_train, y_train = generator_to_numpy(train_generator)\n",
    "X_val, y_val = generator_to_numpy(validation_generator)\n",
    "\n",
    "# Flatten images for logistic regression\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "history_logit = logistic_model.fit(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_model)\n",
    "model_names.append(\"Simple Logistic Regression\")\n",
    "histories.append(history_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_val_scaled = scaler.transform(X_val_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logistic_scaled = LogisticRegression(max_iter=2000, solver='lbfgs')\n",
    "history_logit_scaled = logistic_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_scaled)\n",
    "model_names.append(\"Scaled Logistic Regression\")\n",
    "histories.append(history_logit_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 46ms/step - loss: 0.6934 - accuracy: 0.4583 - val_loss: 0.6930 - val_accuracy: 0.5472\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.6019 - val_loss: 0.6923 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6921 - accuracy: 0.5926 - val_loss: 0.6916 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6914 - accuracy: 0.5926 - val_loss: 0.6909 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.5926 - val_loss: 0.6902 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6903 - accuracy: 0.5926 - val_loss: 0.6896 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5926 - val_loss: 0.6890 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5926 - val_loss: 0.6884 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6886 - accuracy: 0.5926 - val_loss: 0.6878 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6881 - accuracy: 0.5926 - val_loss: 0.6872 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5926 - val_loss: 0.6867 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.5926 - val_loss: 0.6862 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.5926 - val_loss: 0.6857 - val_accuracy: 0.6038\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6863 - accuracy: 0.5926 - val_loss: 0.6852 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6859 - accuracy: 0.5926 - val_loss: 0.6848 - val_accuracy: 0.6038\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6855 - accuracy: 0.5926 - val_loss: 0.6844 - val_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6852 - accuracy: 0.5926 - val_loss: 0.6840 - val_accuracy: 0.6038\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6849 - accuracy: 0.5926 - val_loss: 0.6836 - val_accuracy: 0.6038\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6845 - accuracy: 0.5926 - val_loss: 0.6832 - val_accuracy: 0.6038\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6842 - accuracy: 0.5926 - val_loss: 0.6828 - val_accuracy: 0.6038\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6839 - accuracy: 0.5926 - val_loss: 0.6825 - val_accuracy: 0.6038\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6836 - accuracy: 0.5926 - val_loss: 0.6821 - val_accuracy: 0.6038\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6833 - accuracy: 0.5926 - val_loss: 0.6817 - val_accuracy: 0.6038\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6830 - accuracy: 0.5926 - val_loss: 0.6814 - val_accuracy: 0.6038\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6827 - accuracy: 0.5926 - val_loss: 0.6811 - val_accuracy: 0.6038\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6824 - accuracy: 0.5926 - val_loss: 0.6808 - val_accuracy: 0.6038\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6821 - accuracy: 0.5926 - val_loss: 0.6804 - val_accuracy: 0.6038\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6819 - accuracy: 0.5926 - val_loss: 0.6801 - val_accuracy: 0.6038\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6816 - accuracy: 0.5926 - val_loss: 0.6799 - val_accuracy: 0.6038\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.5926 - val_loss: 0.6796 - val_accuracy: 0.6038\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6812 - accuracy: 0.5926 - val_loss: 0.6793 - val_accuracy: 0.6038\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6810 - accuracy: 0.5926 - val_loss: 0.6791 - val_accuracy: 0.6038\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6808 - accuracy: 0.5926 - val_loss: 0.6789 - val_accuracy: 0.6038\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6806 - accuracy: 0.5926 - val_loss: 0.6786 - val_accuracy: 0.6038\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6804 - accuracy: 0.5926 - val_loss: 0.6784 - val_accuracy: 0.6038\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6803 - accuracy: 0.5926 - val_loss: 0.6782 - val_accuracy: 0.6038\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6801 - accuracy: 0.5926 - val_loss: 0.6780 - val_accuracy: 0.6038\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6800 - accuracy: 0.5926 - val_loss: 0.6778 - val_accuracy: 0.6038\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6797 - accuracy: 0.5926 - val_loss: 0.6776 - val_accuracy: 0.6038\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6796 - accuracy: 0.5926 - val_loss: 0.6774 - val_accuracy: 0.6038\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5926 - val_loss: 0.6773 - val_accuracy: 0.6038\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6793 - accuracy: 0.5926 - val_loss: 0.6770 - val_accuracy: 0.6038\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6791 - accuracy: 0.5926 - val_loss: 0.6769 - val_accuracy: 0.6038\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.5926 - val_loss: 0.6767 - val_accuracy: 0.6038\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.5926 - val_loss: 0.6766 - val_accuracy: 0.6038\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6788 - accuracy: 0.5926 - val_loss: 0.6764 - val_accuracy: 0.6038\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6787 - accuracy: 0.5926 - val_loss: 0.6763 - val_accuracy: 0.6038\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6785 - accuracy: 0.5926 - val_loss: 0.6761 - val_accuracy: 0.6038\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6785 - accuracy: 0.5926 - val_loss: 0.6760 - val_accuracy: 0.6038\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6783 - accuracy: 0.5926 - val_loss: 0.6759 - val_accuracy: 0.6038\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6783 - accuracy: 0.5926 - val_loss: 0.6757 - val_accuracy: 0.6038\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6781 - accuracy: 0.5926 - val_loss: 0.6756 - val_accuracy: 0.6038\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5926 - val_loss: 0.6755 - val_accuracy: 0.6038\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6780 - accuracy: 0.5926 - val_loss: 0.6754 - val_accuracy: 0.6038\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.5926 - val_loss: 0.6753 - val_accuracy: 0.6038\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.5926 - val_loss: 0.6752 - val_accuracy: 0.6038\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6778 - accuracy: 0.5926 - val_loss: 0.6751 - val_accuracy: 0.6038\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6777 - accuracy: 0.5926 - val_loss: 0.6750 - val_accuracy: 0.6038\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6776 - accuracy: 0.5926 - val_loss: 0.6749 - val_accuracy: 0.6038\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6748 - val_accuracy: 0.6038\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6747 - val_accuracy: 0.6038\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6774 - accuracy: 0.5926 - val_loss: 0.6746 - val_accuracy: 0.6038\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6746 - val_accuracy: 0.6038\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6745 - val_accuracy: 0.6038\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6772 - accuracy: 0.5926 - val_loss: 0.6744 - val_accuracy: 0.6038\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6743 - val_accuracy: 0.6038\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6742 - val_accuracy: 0.6038\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6742 - val_accuracy: 0.6038\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6741 - val_accuracy: 0.6038\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6740 - val_accuracy: 0.6038\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6740 - val_accuracy: 0.6038\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6739 - val_accuracy: 0.6038\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6738 - val_accuracy: 0.6038\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6738 - val_accuracy: 0.6038\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.6038\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.6038\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6727 - val_accuracy: 0.6038\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6727 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "x_train_sgd, x_val_sgd = X_train / 255.0, X_val / 255.0\n",
    "\n",
    "# Build model\n",
    "logistic_sgd = Sequential([\n",
    "    Flatten(input_shape = (64, 64, 3)),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "logistic_sgd.compile(optimizer = SGD(), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history_logistic_sgd = logistic_sgd.fit(x_train_sgd, y_train, validation_data=(x_val_sgd, y_val), epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_sgd)\n",
    "model_names.append(\"Logistic Regression - SGD\")\n",
    "histories.append(history_logistic_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "history_svm = svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(svm_model)\n",
    "model_names.append(\"Support Vector Machine\")\n",
    "histories.append(history_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 2.7200 - accuracy: 0.5833 - val_loss: 1.0487 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.7744 - accuracy: 0.5648 - val_loss: 0.6911 - val_accuracy: 0.5094\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.8034 - accuracy: 0.5139 - val_loss: 0.7813 - val_accuracy: 0.3962\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.6890 - accuracy: 0.6204 - val_loss: 0.6353 - val_accuracy: 0.7358\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.6131 - accuracy: 0.6898 - val_loss: 0.5456 - val_accuracy: 0.7358\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.6552 - accuracy: 0.6759 - val_loss: 0.5904 - val_accuracy: 0.7547\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.5914 - accuracy: 0.7130 - val_loss: 0.5779 - val_accuracy: 0.6981\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.6703 - accuracy: 0.6343 - val_loss: 0.6146 - val_accuracy: 0.6981\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.7076 - accuracy: 0.5972 - val_loss: 0.5448 - val_accuracy: 0.7358\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.6381 - accuracy: 0.6435 - val_loss: 0.7973 - val_accuracy: 0.6415\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.7047 - accuracy: 0.6574 - val_loss: 0.8923 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.7538 - accuracy: 0.6296 - val_loss: 0.8995 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.7063 - accuracy: 0.6713 - val_loss: 0.5647 - val_accuracy: 0.7358\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.6043 - accuracy: 0.7037 - val_loss: 0.5821 - val_accuracy: 0.7547\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.5988 - accuracy: 0.6944 - val_loss: 0.5110 - val_accuracy: 0.7170\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.6483 - accuracy: 0.6713 - val_loss: 0.5108 - val_accuracy: 0.7170\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.5908 - accuracy: 0.7037 - val_loss: 0.6600 - val_accuracy: 0.6604\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.6574 - accuracy: 0.6389 - val_loss: 0.7200 - val_accuracy: 0.5849\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.5877 - accuracy: 0.6806 - val_loss: 0.5401 - val_accuracy: 0.7170\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.5995 - accuracy: 0.7083 - val_loss: 0.6053 - val_accuracy: 0.7170\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.5672 - accuracy: 0.6713 - val_loss: 0.5689 - val_accuracy: 0.7736\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6039 - accuracy: 0.6991 - val_loss: 0.5532 - val_accuracy: 0.7358\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.6077 - accuracy: 0.6481 - val_loss: 0.5251 - val_accuracy: 0.7358\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.6054 - accuracy: 0.6574 - val_loss: 0.5525 - val_accuracy: 0.7547\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.5774 - accuracy: 0.7176 - val_loss: 0.5028 - val_accuracy: 0.7925\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.6069 - accuracy: 0.6759 - val_loss: 0.5948 - val_accuracy: 0.6792\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5685 - accuracy: 0.7315 - val_loss: 0.5819 - val_accuracy: 0.6981\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.6263 - accuracy: 0.6991 - val_loss: 0.8601 - val_accuracy: 0.6226\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 0.6180 - accuracy: 0.6759 - val_loss: 0.5842 - val_accuracy: 0.7170\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.5979 - accuracy: 0.6944 - val_loss: 0.5203 - val_accuracy: 0.7547\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.5866 - accuracy: 0.7176 - val_loss: 0.8357 - val_accuracy: 0.5472\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6871 - accuracy: 0.6204 - val_loss: 0.4989 - val_accuracy: 0.7547\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5802 - accuracy: 0.6944 - val_loss: 0.5641 - val_accuracy: 0.7170\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5849 - accuracy: 0.6991 - val_loss: 0.5971 - val_accuracy: 0.6981\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.5947 - accuracy: 0.7222 - val_loss: 0.5716 - val_accuracy: 0.7358\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.6022 - accuracy: 0.6852 - val_loss: 0.5089 - val_accuracy: 0.7925\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.5864 - accuracy: 0.6852 - val_loss: 0.6305 - val_accuracy: 0.6415\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5765 - accuracy: 0.6991 - val_loss: 0.5693 - val_accuracy: 0.6981\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.5781 - accuracy: 0.7222 - val_loss: 0.4872 - val_accuracy: 0.8302\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.5827 - accuracy: 0.6991 - val_loss: 0.5815 - val_accuracy: 0.6415\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.6147 - accuracy: 0.6852 - val_loss: 0.6106 - val_accuracy: 0.6604\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.6208 - accuracy: 0.6620 - val_loss: 0.6545 - val_accuracy: 0.5849\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.6202 - accuracy: 0.6204 - val_loss: 0.5171 - val_accuracy: 0.7736\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 0.5680 - accuracy: 0.7176 - val_loss: 0.4943 - val_accuracy: 0.7358\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5649 - accuracy: 0.7176 - val_loss: 0.5698 - val_accuracy: 0.7170\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.5925 - accuracy: 0.7176 - val_loss: 0.5690 - val_accuracy: 0.7547\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5851 - accuracy: 0.7130 - val_loss: 0.5525 - val_accuracy: 0.7358\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.5820 - accuracy: 0.7083 - val_loss: 0.5200 - val_accuracy: 0.7736\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.5999 - accuracy: 0.6991 - val_loss: 0.4893 - val_accuracy: 0.7358\n"
     ]
    }
   ],
   "source": [
    "model_mlp = Sequential([\n",
    "        Flatten(input_shape = (64, 64, 3)),\n",
    "        Dense(128, activation = 'relu'),\n",
    "        Dense(64, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "model_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_mlp = model_mlp.fit(train_generator, validation_data = validation_generator, epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(model_mlp)\n",
    "model_names.append(\"Multi Layer Perceptron\")\n",
    "histories.append(history_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 147ms/step - loss: 0.6897 - accuracy: 0.5324 - val_loss: 0.6554 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6465 - accuracy: 0.6065 - val_loss: 0.6292 - val_accuracy: 0.7170\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.6022 - accuracy: 0.6620 - val_loss: 0.6446 - val_accuracy: 0.6792\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.5786 - accuracy: 0.6852 - val_loss: 0.5365 - val_accuracy: 0.6981\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5430 - accuracy: 0.7269 - val_loss: 0.5384 - val_accuracy: 0.7547\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.5619 - accuracy: 0.7130 - val_loss: 0.5132 - val_accuracy: 0.7358\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.4987 - accuracy: 0.7685 - val_loss: 0.4588 - val_accuracy: 0.7925\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.4795 - accuracy: 0.7870 - val_loss: 0.5054 - val_accuracy: 0.7170\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.4540 - accuracy: 0.7870 - val_loss: 0.4521 - val_accuracy: 0.7925\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.5047 - accuracy: 0.7824 - val_loss: 0.5190 - val_accuracy: 0.7358\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.4907 - accuracy: 0.7454 - val_loss: 0.4691 - val_accuracy: 0.7736\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.4481 - accuracy: 0.8056 - val_loss: 0.3875 - val_accuracy: 0.8491\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.3890 - accuracy: 0.8241 - val_loss: 0.3687 - val_accuracy: 0.8113\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.3605 - accuracy: 0.8611 - val_loss: 0.3597 - val_accuracy: 0.7925\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.4338 - accuracy: 0.7824 - val_loss: 0.3225 - val_accuracy: 0.8868\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.4185 - accuracy: 0.7963 - val_loss: 0.3893 - val_accuracy: 0.8302\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.3724 - accuracy: 0.8380 - val_loss: 0.3588 - val_accuracy: 0.8679\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.3915 - accuracy: 0.8194 - val_loss: 0.3532 - val_accuracy: 0.8302\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.3530 - accuracy: 0.8565 - val_loss: 0.3529 - val_accuracy: 0.8302\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.3515 - accuracy: 0.8380 - val_loss: 0.4294 - val_accuracy: 0.8113\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.3279 - accuracy: 0.8287 - val_loss: 0.3950 - val_accuracy: 0.8679\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.3265 - accuracy: 0.8426 - val_loss: 0.4355 - val_accuracy: 0.7736\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.3293 - accuracy: 0.8519 - val_loss: 0.4221 - val_accuracy: 0.7736\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.3446 - accuracy: 0.8426 - val_loss: 0.3742 - val_accuracy: 0.8491\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.3237 - accuracy: 0.8472 - val_loss: 0.4360 - val_accuracy: 0.7925\n"
     ]
    }
   ],
   "source": [
    "lenet_model = Sequential([\n",
    "        Conv2D(6, (5, 5), activation = 'relu', padding = 'same', input_shape = (64, 64, 3)),\n",
    "        MaxPooling2D(pool_size = (2, 2)),\n",
    "        Conv2D(16, (5, 5), activation = 'relu'),\n",
    "        MaxPooling2D(pool_size = (2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(120, activation = 'relu'),\n",
    "        Dense(84, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "lenet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "lenet_history = lenet_model.fit(train_generator, validation_data = validation_generator, epochs = 100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(lenet_model)\n",
    "model_names.append(\"LeNet - 5\")\n",
    "histories.append(lenet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 11s 1s/step - loss: 5.1061 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.6942 - accuracy: 0.5694 - val_loss: 0.6901 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.6880 - accuracy: 0.5926 - val_loss: 0.6835 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 414ms/step - loss: 0.6819 - accuracy: 0.5926 - val_loss: 0.6738 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 0.6699 - accuracy: 0.5926 - val_loss: 0.6227 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 0.6113 - accuracy: 0.5926 - val_loss: 0.5340 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.5736 - accuracy: 0.5926 - val_loss: 0.6060 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.6443 - accuracy: 0.5926 - val_loss: 0.5430 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.5495 - accuracy: 0.5926 - val_loss: 0.4815 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 416ms/step - loss: 0.5081 - accuracy: 0.6528 - val_loss: 0.4832 - val_accuracy: 0.7170\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.4998 - accuracy: 0.7130 - val_loss: 0.4833 - val_accuracy: 0.6981\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.5045 - accuracy: 0.7083 - val_loss: 0.4652 - val_accuracy: 0.7170\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.4845 - accuracy: 0.7130 - val_loss: 0.4683 - val_accuracy: 0.7170\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.4774 - accuracy: 0.7130 - val_loss: 0.5276 - val_accuracy: 0.7170\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 406ms/step - loss: 0.5967 - accuracy: 0.6852 - val_loss: 0.5386 - val_accuracy: 0.6415\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 0.4817 - accuracy: 0.7222 - val_loss: 0.4641 - val_accuracy: 0.7547\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.4666 - accuracy: 0.7454 - val_loss: 0.4819 - val_accuracy: 0.7170\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.4564 - accuracy: 0.7407 - val_loss: 0.4794 - val_accuracy: 0.6981\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 0.4598 - accuracy: 0.7361 - val_loss: 0.4558 - val_accuracy: 0.7358\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.5914 - accuracy: 0.7037 - val_loss: 0.4802 - val_accuracy: 0.6981\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.4620 - accuracy: 0.7269 - val_loss: 0.4990 - val_accuracy: 0.6792\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 486ms/step - loss: 0.4598 - accuracy: 0.7222 - val_loss: 0.4631 - val_accuracy: 0.7170\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.4567 - accuracy: 0.7269 - val_loss: 0.5006 - val_accuracy: 0.6792\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.4493 - accuracy: 0.7407 - val_loss: 0.4792 - val_accuracy: 0.6981\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.5022 - accuracy: 0.7130 - val_loss: 0.4970 - val_accuracy: 0.6981\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 0.4921 - accuracy: 0.6991 - val_loss: 0.4774 - val_accuracy: 0.6981\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 0.4480 - accuracy: 0.7593 - val_loss: 1.3303 - val_accuracy: 0.7547\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 0.5269 - accuracy: 0.8056 - val_loss: 0.9480 - val_accuracy: 0.6038\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 0.5053 - accuracy: 0.7407 - val_loss: 0.4722 - val_accuracy: 0.7170\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = Sequential([\n",
    "        Conv2D(96, (11, 11), activation = 'relu', strides = (4, 4), input_shape = (224, 224, 3)),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Conv2D(256, (5, 5), activation = 'relu', padding = 'same'),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Conv2D(384, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(384, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "alexnet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "alexnet_history = alexnet_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(alexnet_model)\n",
    "model_names.append(\"AlexNet\")\n",
    "histories.append(alexnet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 (Without Top)\n",
    "Not able to run in local system - ResourceExhaustedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce batch size to avoid out of memory in GPU (ResourceExhaustedError)\n",
    "\n",
    "# train_generator_vgg16 = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 2, class_mode = 'binary', subset = 'training', seed = 123)\n",
    "# validation_generator_vgg16 = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 2, class_mode = 'binary', subset = 'validation', seed = 123)\n",
    "# test_generator_vgg16 = test_datagen.flow_from_directory(test_dataset_path, target_size = (64, 64), batch_size = 1, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16_base_model = VGG16(weights = 'imagenet', include_top = False, input_shape = (64, 64, 3))\n",
    "\n",
    "# vgg16_model = Sequential([vgg16_base_model, Flatten(), Dense(256, activation = 'relu'), # Dense(512, activation = 'relu'), Dense(1, activation = 'sigmoid')])\n",
    "# vgg16_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# vgg16_history = vgg16_model.fit(train_generator_vgg16, validation_data = validation_generator_vgg16, epochs = 100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "# train_generator_vgg16 = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 2, class_mode = 'binary', subset = 'training', seed = 123)\n",
    "# validation_generator_vgg16 = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 2, class_mode = 'binary', subset = 'validation', seed = 123)\n",
    "# test_generator_vgg16 = test_datagen.flow_from_directory(test_dataset_path, target_size = (64, 64), batch_size = 1, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16_base_model = VGG16(weights='imagenet', include_top = False, input_shape = (64, 64, 3))\n",
    "# vgg16_model = Sequential([vgg16_base_model, Flatten(), Dense(512, activation = 'relu'), Dense(512, activation = 'relu'), Dense(1, activation = 'sigmoid', dtype = tf.float32)  # Ensure the output is float32])\n",
    "# Use 'mixed_float16' optimizer to align with the mixed precision policy\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "# vgg16_model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# vgg16_history = vgg16_model.fit(train_generator_vgg16, validation_data = validation_generator_vgg16, epochs = 100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce batch size to avoid out of memory in GPU (ResourceExhaustedError)\n",
    "# train_generator_vgg16 = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 16, class_mode = 'binary', subset = 'training', seed = 123)\n",
    "# validation_generator_vgg16 = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 16, class_mode = 'binary', subset = 'validation', seed = 123)\n",
    "# test_generator_vgg16 = test_datagen.flow_from_directory(test_dataset_path, target_size = (64, 64), batch_size = 1, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPU\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "# vgg16_base_model = VGG16(weights = 'imagenet', include_top = False, input_shape = (64, 64, 3))\n",
    "# vgg16_model = Sequential([vgg16_base_model, Flatten(), Dense(512, activation = 'relu'), Dense(512, activation = 'relu'), Dense(1, activation = 'sigmoid')])\n",
    "# vgg16_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# Train the model on CPU\n",
    "# with tf.device('/CPU:0'):\n",
    "#    vgg16_history = vgg16_model.fit(train_generator_vgg16, validation_data = validation_generator_vgg16, \n",
    "#                                    epochs = 100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(vgg16_model)\n",
    "# model_names.append(\"VGG16 (Without Top)\")\n",
    "# histories.append(vgg16_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm1S5n-jo9PU"
   },
   "source": [
    "#### Evaluating the neural netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model and store results\n",
    "for i, (model, model_name, history) in enumerate(zip(models, model_names, histories)):\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    metrics = evaluate_model(model, validation_generator)\n",
    "    \n",
    "    # Print metrics for comparison\n",
    "    print(f\"Metrics for {model_name}:\")\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics['classification_report'])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(metrics['confusion_matrix'], validation_generator.class_indices.keys(), model_name)\n",
    "\n",
    "    # Plot metrics if you have a history object\n",
    "    plot_metrics(history, model_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
