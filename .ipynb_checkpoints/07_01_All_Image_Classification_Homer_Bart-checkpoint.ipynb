{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7znwBf0O6tpE"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import zipfile\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "dVfbaWDe8htY",
    "outputId": "998eef1f-4222-47d1-8f7f-51554c345742"
   },
   "outputs": [],
   "source": [
    "# path='/content/homer_bart_2.zip'\n",
    "\n",
    "# zip_obect=zipfile.ZipFile(file=path,mode='r')\n",
    "# zip_obect.extractall('./')\n",
    "# zip_obect.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = []\n",
    "histories = []\n",
    "\n",
    "# Function to evaluate a model and return metrics\n",
    "def evaluate_model(model, validation_generator):\n",
    "    # Evaluate the model on the validation data\n",
    "    val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    val_steps = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "    predictions = model.predict(validation_generator, steps=val_steps)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = validation_generator.classes\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(true_classes, predicted_classes, target_names=validation_generator.class_indices.keys(), output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': val_accuracy,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "\n",
    "# Function to plot validation loss and accuracy\n",
    "def plot_metrics(history, model_name):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['val_loss'], label=f'Validation Loss ({model_name})')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['val_accuracy'], label=f'Validation Accuracy ({model_name})')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix ({model_name})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHYWcwOTfIMP"
   },
   "source": [
    "#### Preprocessing on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "(64, 64, 3)\n",
      "{'bart': 0, 'homer': 1}\n",
      "{'bart': 0, 'homer': 1}\n",
      "{}\n",
      "(224, 224, 3)\n",
      "{'bart': 0, 'homer': 1}\n",
      "{'bart': 0, 'homer': 1}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your dataset\n",
    "dataset_path = 'homer_bart_1'\n",
    "\n",
    "# Create an ImageDataGenerator for training with data augmentation and validation split\n",
    "datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 20, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, validation_split = 0.2)\n",
    "\n",
    "# Load training data with augmentation\n",
    "train_generator = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Load training data with augmentation\n",
    "train_generator_224 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator_224 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Create a separate ImageDataGenerator for test data (only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Define the path to your test dataset\n",
    "test_dataset_path = 'test_dataset'\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(test_dataset_path, target_size = (64, 64), batch_size = 1, class_mode = 'binary')\n",
    "test_generator_244 = test_datagen.flow_from_directory(test_dataset_path, target_size = (224, 224), batch_size = 1, class_mode = 'binary')\n",
    "\n",
    "# Print class indices\n",
    "print(\"(64, 64, 3)\")\n",
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)\n",
    "\n",
    "print(\"(224, 224, 3)\")\n",
    "print(train_generator_224.class_indices)\n",
    "print(validation_generator_224.class_indices)\n",
    "print(test_generator_244.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSqnbI1VjU5J"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D Model (Checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EccXSMwHi4RI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 683,329\n",
      "Trainable params: 683,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model_check = Sequential([\n",
    "    layers.InputLayer(input_shape = (64, 64, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(1, activation = 'sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model_check.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG-9aj9RknrC",
    "outputId": "f638a7c7-3f2c-4e78-81d0-4fea757c475b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 8s 177ms/step - loss: 0.7554 - accuracy: 0.5324 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.6859 - accuracy: 0.5926 - val_loss: 0.6659 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.6590 - accuracy: 0.5926 - val_loss: 0.6460 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6446 - accuracy: 0.5926 - val_loss: 0.6074 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6027 - accuracy: 0.6574 - val_loss: 0.5769 - val_accuracy: 0.8113\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.5359 - accuracy: 0.7593 - val_loss: 0.5252 - val_accuracy: 0.7547\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.4696 - accuracy: 0.7824 - val_loss: 0.5022 - val_accuracy: 0.7925\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.4694 - accuracy: 0.7731 - val_loss: 0.5440 - val_accuracy: 0.7547\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.4627 - accuracy: 0.7870 - val_loss: 0.4742 - val_accuracy: 0.7736\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.3966 - accuracy: 0.8009 - val_loss: 0.4371 - val_accuracy: 0.7736\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.4206 - accuracy: 0.7778 - val_loss: 0.5280 - val_accuracy: 0.6981\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.4043 - accuracy: 0.8102 - val_loss: 0.4559 - val_accuracy: 0.7736\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 0.3283 - accuracy: 0.8565 - val_loss: 0.4219 - val_accuracy: 0.7925\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.3789 - accuracy: 0.8056 - val_loss: 0.5233 - val_accuracy: 0.7547\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.3634 - accuracy: 0.8102 - val_loss: 0.5491 - val_accuracy: 0.7170\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.4360 - accuracy: 0.7593 - val_loss: 0.5238 - val_accuracy: 0.6792\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.4332 - accuracy: 0.7361 - val_loss: 0.4646 - val_accuracy: 0.7358\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.3998 - accuracy: 0.8102 - val_loss: 0.4761 - val_accuracy: 0.7736\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.3444 - accuracy: 0.8611 - val_loss: 0.4746 - val_accuracy: 0.8113\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.3301 - accuracy: 0.8333 - val_loss: 0.4230 - val_accuracy: 0.7736\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.3363 - accuracy: 0.8380 - val_loss: 0.4143 - val_accuracy: 0.7925\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.2878 - accuracy: 0.8843 - val_loss: 0.4001 - val_accuracy: 0.7736\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.2652 - accuracy: 0.8935 - val_loss: 0.4442 - val_accuracy: 0.7925\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.2875 - accuracy: 0.8241 - val_loss: 0.4048 - val_accuracy: 0.8302\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.2964 - accuracy: 0.8426 - val_loss: 0.5303 - val_accuracy: 0.7547\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.3009 - accuracy: 0.8750 - val_loss: 0.3862 - val_accuracy: 0.7736\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.2702 - accuracy: 0.8981 - val_loss: 0.4885 - val_accuracy: 0.8113\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.2431 - accuracy: 0.8889 - val_loss: 0.3690 - val_accuracy: 0.8679\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.2860 - accuracy: 0.8935 - val_loss: 0.4071 - val_accuracy: 0.7736\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.2751 - accuracy: 0.8889 - val_loss: 0.4261 - val_accuracy: 0.7925\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.2340 - accuracy: 0.8935 - val_loss: 0.3911 - val_accuracy: 0.7925\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.2462 - accuracy: 0.8889 - val_loss: 0.4837 - val_accuracy: 0.8491\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.2142 - accuracy: 0.9352 - val_loss: 0.4276 - val_accuracy: 0.8302\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.1956 - accuracy: 0.9167 - val_loss: 0.3509 - val_accuracy: 0.8302\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.2197 - accuracy: 0.8981 - val_loss: 0.4457 - val_accuracy: 0.8679\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.2217 - accuracy: 0.9213 - val_loss: 0.3870 - val_accuracy: 0.8302\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.2061 - accuracy: 0.8981 - val_loss: 0.4264 - val_accuracy: 0.8491\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.2149 - accuracy: 0.9120 - val_loss: 0.4682 - val_accuracy: 0.8113\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.2170 - accuracy: 0.8981 - val_loss: 0.4461 - val_accuracy: 0.7925\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.2006 - accuracy: 0.9352 - val_loss: 0.5068 - val_accuracy: 0.8302\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.1848 - accuracy: 0.9259 - val_loss: 0.3654 - val_accuracy: 0.8113\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 0.1614 - accuracy: 0.9306 - val_loss: 0.4617 - val_accuracy: 0.8302\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.1301 - accuracy: 0.9537 - val_loss: 0.4915 - val_accuracy: 0.8302\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.1310 - accuracy: 0.9491 - val_loss: 0.3766 - val_accuracy: 0.8679\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_check.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True)\n",
    "history_check = model_check.fit(train_generator, validation_data = validation_generator, epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(model_check)\n",
    "model_names.append(\"Conv2D Check\")\n",
    "histories.append(history_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from generators to numpy arrays\n",
    "\n",
    "def generator_to_numpy(generator):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for _ in range(len(generator)):\n",
    "        img_batch, label_batch = next(generator)\n",
    "        images.extend(img_batch)\n",
    "        labels.extend(label_batch)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation data as numpy arrays\n",
    "X_train, y_train = generator_to_numpy(train_generator)\n",
    "X_val, y_val = generator_to_numpy(validation_generator)\n",
    "\n",
    "# Flatten images for logistic regression\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "history_logit = logistic_model.fit(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_model)\n",
    "model_names.append(\"Simple Logistic Regression\")\n",
    "histories.append(history_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_val_scaled = scaler.transform(X_val_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logistic_scaled = LogisticRegression(max_iter=2000, solver='lbfgs')\n",
    "history_logit_scaled = logistic_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_scaled)\n",
    "model_names.append(\"Scaled Logistic Regression\")\n",
    "histories.append(history_logit_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 42ms/step - loss: 0.6929 - accuracy: 0.5648 - val_loss: 0.6923 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6922 - accuracy: 0.5926 - val_loss: 0.6916 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6916 - accuracy: 0.5926 - val_loss: 0.6909 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6910 - accuracy: 0.5926 - val_loss: 0.6903 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6904 - accuracy: 0.5926 - val_loss: 0.6897 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.5926 - val_loss: 0.6891 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5926 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6888 - accuracy: 0.5926 - val_loss: 0.6879 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6884 - accuracy: 0.5926 - val_loss: 0.6873 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5926 - val_loss: 0.6868 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6874 - accuracy: 0.5926 - val_loss: 0.6863 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6870 - accuracy: 0.5926 - val_loss: 0.6858 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6865 - accuracy: 0.5926 - val_loss: 0.6853 - val_accuracy: 0.6038\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6861 - accuracy: 0.5926 - val_loss: 0.6849 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.5926 - val_loss: 0.6844 - val_accuracy: 0.6038\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6853 - accuracy: 0.5926 - val_loss: 0.6840 - val_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6850 - accuracy: 0.5926 - val_loss: 0.6837 - val_accuracy: 0.6038\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6847 - accuracy: 0.5926 - val_loss: 0.6833 - val_accuracy: 0.6038\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6844 - accuracy: 0.5926 - val_loss: 0.6829 - val_accuracy: 0.6038\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6841 - accuracy: 0.5926 - val_loss: 0.6825 - val_accuracy: 0.6038\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5926 - val_loss: 0.6822 - val_accuracy: 0.6038\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5926 - val_loss: 0.6818 - val_accuracy: 0.6038\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6832 - accuracy: 0.5926 - val_loss: 0.6815 - val_accuracy: 0.6038\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6828 - accuracy: 0.5926 - val_loss: 0.6811 - val_accuracy: 0.6038\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6825 - accuracy: 0.5926 - val_loss: 0.6808 - val_accuracy: 0.6038\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6823 - accuracy: 0.5926 - val_loss: 0.6805 - val_accuracy: 0.6038\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5926 - val_loss: 0.6803 - val_accuracy: 0.6038\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5926 - val_loss: 0.6800 - val_accuracy: 0.6038\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6816 - accuracy: 0.5926 - val_loss: 0.6797 - val_accuracy: 0.6038\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.5926 - val_loss: 0.6795 - val_accuracy: 0.6038\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5926 - val_loss: 0.6792 - val_accuracy: 0.6038\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5926 - val_loss: 0.6790 - val_accuracy: 0.6038\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5926 - val_loss: 0.6787 - val_accuracy: 0.6038\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5926 - val_loss: 0.6785 - val_accuracy: 0.6038\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5926 - val_loss: 0.6783 - val_accuracy: 0.6038\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5926 - val_loss: 0.6781 - val_accuracy: 0.6038\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6801 - accuracy: 0.5926 - val_loss: 0.6779 - val_accuracy: 0.6038\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5926 - val_loss: 0.6778 - val_accuracy: 0.6038\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5926 - val_loss: 0.6776 - val_accuracy: 0.6038\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5926 - val_loss: 0.6774 - val_accuracy: 0.6038\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5926 - val_loss: 0.6772 - val_accuracy: 0.6038\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5926 - val_loss: 0.6771 - val_accuracy: 0.6038\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5926 - val_loss: 0.6769 - val_accuracy: 0.6038\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.5926 - val_loss: 0.6767 - val_accuracy: 0.6038\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.5926 - val_loss: 0.6766 - val_accuracy: 0.6038\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5926 - val_loss: 0.6765 - val_accuracy: 0.6038\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5926 - val_loss: 0.6763 - val_accuracy: 0.6038\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5926 - val_loss: 0.6762 - val_accuracy: 0.6038\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5926 - val_loss: 0.6761 - val_accuracy: 0.6038\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6784 - accuracy: 0.5926 - val_loss: 0.6760 - val_accuracy: 0.6038\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5926 - val_loss: 0.6759 - val_accuracy: 0.6038\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5926 - val_loss: 0.6757 - val_accuracy: 0.6038\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5926 - val_loss: 0.6756 - val_accuracy: 0.6038\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6781 - accuracy: 0.5926 - val_loss: 0.6755 - val_accuracy: 0.6038\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5926 - val_loss: 0.6754 - val_accuracy: 0.6038\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6779 - accuracy: 0.5926 - val_loss: 0.6753 - val_accuracy: 0.6038\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.5926 - val_loss: 0.6752 - val_accuracy: 0.6038\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6778 - accuracy: 0.5926 - val_loss: 0.6751 - val_accuracy: 0.6038\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6777 - accuracy: 0.5926 - val_loss: 0.6750 - val_accuracy: 0.6038\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6777 - accuracy: 0.5926 - val_loss: 0.6750 - val_accuracy: 0.6038\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6776 - accuracy: 0.5926 - val_loss: 0.6749 - val_accuracy: 0.6038\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6748 - val_accuracy: 0.6038\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6747 - val_accuracy: 0.6038\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6746 - val_accuracy: 0.6038\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5926 - val_loss: 0.6746 - val_accuracy: 0.6038\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6745 - val_accuracy: 0.6038\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6744 - val_accuracy: 0.6038\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5926 - val_loss: 0.6743 - val_accuracy: 0.6038\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6772 - accuracy: 0.5926 - val_loss: 0.6743 - val_accuracy: 0.6038\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6742 - val_accuracy: 0.6038\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6741 - val_accuracy: 0.6038\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6741 - val_accuracy: 0.6038\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6740 - val_accuracy: 0.6038\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6739 - val_accuracy: 0.6038\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6739 - val_accuracy: 0.6038\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6738 - val_accuracy: 0.6038\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6738 - val_accuracy: 0.6038\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.6038\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.6038\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "x_train_sgd, x_val_sgd = X_train / 255.0, X_val / 255.0\n",
    "\n",
    "# Build model\n",
    "logistic_sgd = Sequential([\n",
    "    Flatten(input_shape = (64, 64, 3)),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "logistic_sgd.compile(optimizer = SGD(), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history_logistic_sgd = logistic_sgd.fit(x_train_sgd, y_train, validation_data=(x_val_sgd, y_val), epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_sgd)\n",
    "model_names.append(\"Logistic Regression - SGD\")\n",
    "histories.append(history_logistic_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "history_svm = svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(svm_model)\n",
    "model_names.append(\"Support Vector Machine\")\n",
    "histories.append(history_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 129ms/step - loss: 2.2882 - accuracy: 0.5000 - val_loss: 1.4348 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 1.1662 - accuracy: 0.5463 - val_loss: 0.8311 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.7791 - accuracy: 0.5278 - val_loss: 0.6232 - val_accuracy: 0.6226\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.6625 - accuracy: 0.6250 - val_loss: 0.6653 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6812 - accuracy: 0.6019 - val_loss: 0.5764 - val_accuracy: 0.7170\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.7294 - accuracy: 0.6111 - val_loss: 0.5848 - val_accuracy: 0.7358\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.5931 - accuracy: 0.6944 - val_loss: 0.6083 - val_accuracy: 0.6792\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 0.7274 - accuracy: 0.6389 - val_loss: 0.5491 - val_accuracy: 0.7736\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.7394 - accuracy: 0.6111 - val_loss: 0.7713 - val_accuracy: 0.6226\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6617 - accuracy: 0.6852 - val_loss: 0.5526 - val_accuracy: 0.7358\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.7747 - accuracy: 0.5833 - val_loss: 0.6342 - val_accuracy: 0.6792\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.6982 - accuracy: 0.6435 - val_loss: 0.7236 - val_accuracy: 0.6792\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.7662 - accuracy: 0.6296 - val_loss: 0.7863 - val_accuracy: 0.6604\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.6530 - accuracy: 0.6667 - val_loss: 0.5029 - val_accuracy: 0.7925\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6075 - accuracy: 0.6620 - val_loss: 0.5856 - val_accuracy: 0.6981\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 0.6121 - accuracy: 0.6667 - val_loss: 0.5654 - val_accuracy: 0.7170\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.6005 - accuracy: 0.6759 - val_loss: 0.6089 - val_accuracy: 0.6792\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.6119 - accuracy: 0.6806 - val_loss: 0.7309 - val_accuracy: 0.6226\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.6097 - accuracy: 0.6806 - val_loss: 0.5024 - val_accuracy: 0.7358\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6610 - accuracy: 0.6435 - val_loss: 0.5426 - val_accuracy: 0.7170\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.7115 - accuracy: 0.6250 - val_loss: 0.6388 - val_accuracy: 0.6981\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6918 - accuracy: 0.6435 - val_loss: 0.6567 - val_accuracy: 0.6981\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.6899 - accuracy: 0.6435 - val_loss: 0.6130 - val_accuracy: 0.7170\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.8058 - accuracy: 0.6157 - val_loss: 0.6436 - val_accuracy: 0.6415\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6241 - accuracy: 0.6944 - val_loss: 0.5375 - val_accuracy: 0.7925\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.5929 - accuracy: 0.6759 - val_loss: 0.5072 - val_accuracy: 0.7925\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.6062 - accuracy: 0.7315 - val_loss: 0.5710 - val_accuracy: 0.7170\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6118 - accuracy: 0.7037 - val_loss: 0.6165 - val_accuracy: 0.7170\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6157 - accuracy: 0.6898 - val_loss: 0.5533 - val_accuracy: 0.6981\n"
     ]
    }
   ],
   "source": [
    "model_mlp = Sequential([\n",
    "        Flatten(input_shape = (64, 64, 3)),\n",
    "        Dense(128, activation = 'relu'),\n",
    "        Dense(64, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "model_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_mlp = model_mlp.fit(train_generator, validation_data = validation_generator, epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(model_mlp)\n",
    "model_names.append(\"Multi Layer Perceptron\")\n",
    "histories.append(history_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 123ms/step - loss: 0.7287 - accuracy: 0.5417 - val_loss: 0.6824 - val_accuracy: 0.5094\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6682 - accuracy: 0.5972 - val_loss: 0.6530 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.6421 - accuracy: 0.6389 - val_loss: 0.6095 - val_accuracy: 0.7547\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.6044 - accuracy: 0.6759 - val_loss: 0.7039 - val_accuracy: 0.5094\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6518 - accuracy: 0.5926 - val_loss: 0.6095 - val_accuracy: 0.6226\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.5872 - accuracy: 0.6574 - val_loss: 0.6007 - val_accuracy: 0.7170\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.5757 - accuracy: 0.7083 - val_loss: 0.5304 - val_accuracy: 0.7547\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.5132 - accuracy: 0.7546 - val_loss: 0.4761 - val_accuracy: 0.8113\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.5598 - accuracy: 0.7176 - val_loss: 0.5366 - val_accuracy: 0.7925\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.5247 - accuracy: 0.7639 - val_loss: 0.5548 - val_accuracy: 0.7358\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.5147 - accuracy: 0.7315 - val_loss: 0.5039 - val_accuracy: 0.8113\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.5291 - accuracy: 0.7407 - val_loss: 0.4894 - val_accuracy: 0.8113\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.5308 - accuracy: 0.7315 - val_loss: 0.5422 - val_accuracy: 0.7358\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.4874 - accuracy: 0.7639 - val_loss: 0.4874 - val_accuracy: 0.7925\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.4867 - accuracy: 0.7639 - val_loss: 0.5408 - val_accuracy: 0.6792\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.5005 - accuracy: 0.7454 - val_loss: 0.5418 - val_accuracy: 0.8113\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.4838 - accuracy: 0.7731 - val_loss: 0.5365 - val_accuracy: 0.7170\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 0.5077 - accuracy: 0.7963 - val_loss: 0.4873 - val_accuracy: 0.7358\n"
     ]
    }
   ],
   "source": [
    "lenet_model = Sequential([\n",
    "        Conv2D(6, (5, 5), activation = 'relu', padding = 'same', input_shape = (64, 64, 3)),\n",
    "        MaxPooling2D(pool_size = (2, 2)),\n",
    "        Conv2D(16, (5, 5), activation = 'relu'),\n",
    "        MaxPooling2D(pool_size = (2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(120, activation = 'relu'),\n",
    "        Dense(84, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "lenet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "lenet_history = lenet_model.fit(train_generator, validation_data = validation_generator, epochs = 100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(lenet_model)\n",
    "model_names.append(\"LeNet - 5\")\n",
    "histories.append(lenet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 6s 629ms/step - loss: 3.7048 - accuracy: 0.5833 - val_loss: 0.6766 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 381ms/step - loss: 0.7047 - accuracy: 0.5926 - val_loss: 0.6810 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 401ms/step - loss: 0.6909 - accuracy: 0.5880 - val_loss: 0.6887 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.6860 - accuracy: 0.5926 - val_loss: 0.6792 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.6786 - accuracy: 0.5926 - val_loss: 0.6726 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 377ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 399ms/step - loss: 0.6754 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 413ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 367ms/step - loss: 0.6751 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 392ms/step - loss: 0.6751 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 376ms/step - loss: 0.6752 - accuracy: 0.5926 - val_loss: 0.6716 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 393ms/step - loss: 0.6759 - accuracy: 0.5926 - val_loss: 0.6725 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 384ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 384ms/step - loss: 0.6772 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.6756 - accuracy: 0.5926 - val_loss: 0.6716 - val_accuracy: 0.6038\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 369ms/step - loss: 0.6760 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 394ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = Sequential([\n",
    "        Conv2D(96, (11, 11), activation = 'relu', strides = (4, 4), input_shape = (224, 224, 3)),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Conv2D(256, (5, 5), activation = 'relu', padding = 'same'),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Conv2D(384, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(384, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "alexnet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "alexnet_history = alexnet_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(alexnet_model)\n",
    "model_names.append(\"AlexNet\")\n",
    "histories.append(alexnet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 (Without Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 35s 3s/step - loss: 6.9308 - accuracy: 0.5509 - val_loss: 2.7207 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 1.0833 - accuracy: 0.5139 - val_loss: 0.6934 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 0.6857 - accuracy: 0.5556 - val_loss: 0.6663 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 465ms/step - loss: 0.6653 - accuracy: 0.6019 - val_loss: 0.6597 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.6911 - accuracy: 0.5463 - val_loss: 0.6940 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 474ms/step - loss: 0.6803 - accuracy: 0.5556 - val_loss: 0.6501 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 471ms/step - loss: 0.6820 - accuracy: 0.5926 - val_loss: 0.6466 - val_accuracy: 0.5094\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.6680 - accuracy: 0.5602 - val_loss: 0.5901 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.5937 - accuracy: 0.6204 - val_loss: 0.5043 - val_accuracy: 0.7358\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 0.5499 - accuracy: 0.6806 - val_loss: 0.5416 - val_accuracy: 0.6792\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 455ms/step - loss: 0.5069 - accuracy: 0.7315 - val_loss: 0.4958 - val_accuracy: 0.8113\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 462ms/step - loss: 0.4537 - accuracy: 0.7546 - val_loss: 0.4712 - val_accuracy: 0.7925\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.4211 - accuracy: 0.7454 - val_loss: 0.5410 - val_accuracy: 0.7170\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 0.3956 - accuracy: 0.7963 - val_loss: 0.6016 - val_accuracy: 0.7547\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.4285 - accuracy: 0.7824 - val_loss: 0.4629 - val_accuracy: 0.7547\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.4702 - accuracy: 0.7500 - val_loss: 0.4944 - val_accuracy: 0.6981\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.5333 - accuracy: 0.7130 - val_loss: 0.5989 - val_accuracy: 0.6792\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 0.5327 - accuracy: 0.7454 - val_loss: 0.5879 - val_accuracy: 0.6415\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 432ms/step - loss: 0.5194 - accuracy: 0.7222 - val_loss: 1.0731 - val_accuracy: 0.5849\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 0.7099 - accuracy: 0.6204 - val_loss: 0.6308 - val_accuracy: 0.6415\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.5625 - accuracy: 0.6620 - val_loss: 0.4656 - val_accuracy: 0.7547\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 458ms/step - loss: 0.4579 - accuracy: 0.7130 - val_loss: 0.4740 - val_accuracy: 0.6981\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 0.4471 - accuracy: 0.7593 - val_loss: 0.5703 - val_accuracy: 0.7170\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 0.4215 - accuracy: 0.7685 - val_loss: 0.4599 - val_accuracy: 0.8113\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 0.3690 - accuracy: 0.8333 - val_loss: 0.4047 - val_accuracy: 0.7547\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.3514 - accuracy: 0.8380 - val_loss: 0.3257 - val_accuracy: 0.8302\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.4174 - accuracy: 0.8102 - val_loss: 0.4238 - val_accuracy: 0.7547\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.4341 - accuracy: 0.7222 - val_loss: 0.4191 - val_accuracy: 0.7736\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.4787 - val_accuracy: 0.7170\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 3s 463ms/step - loss: 0.3804 - accuracy: 0.8380 - val_loss: 0.4808 - val_accuracy: 0.7358\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 0.4204 - accuracy: 0.7870 - val_loss: 0.4083 - val_accuracy: 0.7547\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.4861 - accuracy: 0.7315 - val_loss: 0.4981 - val_accuracy: 0.6981\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.4608 - accuracy: 0.7407 - val_loss: 0.5083 - val_accuracy: 0.6981\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.5170 - accuracy: 0.7546 - val_loss: 0.4844 - val_accuracy: 0.6981\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.4611 - accuracy: 0.7407 - val_loss: 0.4439 - val_accuracy: 0.7547\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 3s 457ms/step - loss: 0.3945 - accuracy: 0.8287 - val_loss: 0.4395 - val_accuracy: 0.7547\n"
     ]
    }
   ],
   "source": [
    "# Load VGG16 model\n",
    "base_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Build model\n",
    "vgg_16_model = Sequential([\n",
    "    base_vgg16,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_16_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg16_history = vgg_16_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(vgg_16_model)\n",
    "model_names.append(\"VGG16\")\n",
    "histories.append(vgg16_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 (Without Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 6s 632ms/step - loss: 2.1533 - accuracy: 0.5324 - val_loss: 0.8245 - val_accuracy: 0.3962\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 4s 539ms/step - loss: 0.7908 - accuracy: 0.5741 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 4s 532ms/step - loss: 0.7220 - accuracy: 0.5648 - val_loss: 0.6811 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 0.8046 - accuracy: 0.5694 - val_loss: 0.6739 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 4s 537ms/step - loss: 0.6935 - accuracy: 0.5694 - val_loss: 0.6962 - val_accuracy: 0.3962\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 525ms/step - loss: 0.6922 - accuracy: 0.5463 - val_loss: 0.6725 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 4s 524ms/step - loss: 0.6729 - accuracy: 0.5926 - val_loss: 0.6718 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 540ms/step - loss: 0.6799 - accuracy: 0.5926 - val_loss: 0.6716 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 4s 519ms/step - loss: 0.6885 - accuracy: 0.5556 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 0.6801 - accuracy: 0.5926 - val_loss: 0.6796 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 4s 528ms/step - loss: 0.6820 - accuracy: 0.5972 - val_loss: 0.6749 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 0.6817 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 0.6783 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 0.6795 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 0.6805 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 4s 527ms/step - loss: 0.6777 - accuracy: 0.5926 - val_loss: 0.6719 - val_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 534ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 538ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6722 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Build model\n",
    "vgg_19_model = Sequential([\n",
    "    base_vgg19,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_19_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg19_history = vgg_19_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(vgg_19_model)\n",
    "model_names.append(\"VGG19\")\n",
    "histories.append(vgg19_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 319s 1us/step\n",
      "Epoch 1/100\n",
      "1/7 [===>..........................] - ETA: 12s - loss: 0.6933 - accuracy: 0.4583"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential_8/vgg16/fc1/MatMul/MatMul_1' defined at (most recent call last):\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_17168\\2414197923.py\", line 15, in <module>\n      vgg16_history_2 = vgg_16_model_2.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100,\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_8/vgg16/fc1/MatMul/MatMul_1'\nOOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential_8/vgg16/fc1/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_31643]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m vgg_16_model_2\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m vgg16_history_2 \u001b[38;5;241m=\u001b[39m \u001b[43mvgg_16_model_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator_224\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator_224\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential_8/vgg16/fc1/MatMul/MatMul_1' defined at (most recent call last):\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_17168\\2414197923.py\", line 15, in <module>\n      vgg16_history_2 = vgg_16_model_2.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100,\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_8/vgg16/fc1/MatMul/MatMul_1'\nOOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential_8/vgg16/fc1/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_31643]"
     ]
    }
   ],
   "source": [
    "# Load VGG16 model\n",
    "base_vgg16_2 = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "# Build model\n",
    "vgg_16_model_2 = Sequential([\n",
    "    base_vgg16_2,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_16_model_2.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg16_history_2 = vgg_16_model_2.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(vgg_16_model_2)\n",
    "model_names.append(\"VGG16_2\")\n",
    "histories.append(vgg16_history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vgg19_2 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Build model\n",
    "vgg_19_model_2 = Sequential([\n",
    "    base_vgg19_2,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_19_model_2.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg19_history_2 = vgg_19_model_2.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(vgg_19_model_2)\n",
    "model_names.append(\"VGG19_2\")\n",
    "histories.append(vgg19_history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm1S5n-jo9PU"
   },
   "source": [
    "#### Evaluating the neural netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model and store results\n",
    "for i, (model, model_name, history) in enumerate(zip(models, model_names, histories)):\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    metrics = evaluate_model(model, validation_generator)\n",
    "    \n",
    "    # Print metrics for comparison\n",
    "    print(f\"Metrics for {model_name}:\")\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics['classification_report'])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(metrics['confusion_matrix'], validation_generator.class_indices.keys(), model_name)\n",
    "\n",
    "    # Plot metrics if you have a history object\n",
    "    plot_metrics(history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
