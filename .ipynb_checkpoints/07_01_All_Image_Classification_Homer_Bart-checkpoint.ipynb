{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "7znwBf0O6tpE"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import zipfile\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import History\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.applications import DenseNet121, EfficientNetB0, InceptionV3, MobileNet, ResNet50, VGG16, VGG19\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "dVfbaWDe8htY",
    "outputId": "998eef1f-4222-47d1-8f7f-51554c345742"
   },
   "outputs": [],
   "source": [
    "# path='/content/homer_bart_2.zip'\n",
    "\n",
    "# zip_obect=zipfile.ZipFile(file=path,mode='r')\n",
    "# zip_obect.extractall('./')\n",
    "# zip_obect.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = []\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHYWcwOTfIMP"
   },
   "source": [
    "#### Preprocessing on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "(64, 64, 3)\n",
      "{'bart': 0, 'homer': 1}\n",
      "{'bart': 0, 'homer': 1}\n",
      "{}\n",
      "(224, 224, 3)\n",
      "{'bart': 0, 'homer': 1}\n",
      "{'bart': 0, 'homer': 1}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your dataset\n",
    "dataset_path = 'homer_bart_1'\n",
    "\n",
    "# Create an ImageDataGenerator for training with data augmentation and validation split\n",
    "datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 20, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, validation_split = 0.2)\n",
    "\n",
    "# Load training data with augmentation\n",
    "train_generator = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Load training data with augmentation\n",
    "train_generator_224 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator_224 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Load training data with augmentation and reduced batch size\n",
    "train_generator_224_8 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 2, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator_224_8 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 2, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Load training data with augmentation and reduced batch size\n",
    "train_generator_299 = datagen.flow_from_directory(dataset_path, target_size = (299, 299), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator_299 = datagen.flow_from_directory(dataset_path, target_size = (299, 299), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Create a separate ImageDataGenerator for test data (only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Define the path to your test dataset\n",
    "test_dataset_path = 'test_dataset'\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(test_dataset_path, target_size = (64, 64), batch_size = 1, class_mode = 'binary')\n",
    "test_generator_244 = test_datagen.flow_from_directory(test_dataset_path, target_size = (224, 224), batch_size = 1, class_mode = 'binary')\n",
    "\n",
    "# Print class indices\n",
    "print(\"(64, 64, 3)\")\n",
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)\n",
    "\n",
    "print(\"(224, 224, 3)\")\n",
    "print(train_generator_224.class_indices)\n",
    "print(validation_generator_224.class_indices)\n",
    "print(test_generator_244.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSqnbI1VjU5J"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D Model (Checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EccXSMwHi4RI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 683,329\n",
      "Trainable params: 683,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model_check = Sequential([\n",
    "    layers.InputLayer(input_shape = (64, 64, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(1, activation = 'sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model_check.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG-9aj9RknrC",
    "outputId": "f638a7c7-3f2c-4e78-81d0-4fea757c475b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 77ms/step - loss: 0.7493 - accuracy: 0.4444 - val_loss: 0.6869 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6871 - accuracy: 0.5972 - val_loss: 0.6675 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6728 - accuracy: 0.5926 - val_loss: 0.6562 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.6571 - accuracy: 0.5972 - val_loss: 0.6324 - val_accuracy: 0.6981\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6316 - accuracy: 0.6528 - val_loss: 0.5955 - val_accuracy: 0.6792\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.6259 - accuracy: 0.6528 - val_loss: 0.5920 - val_accuracy: 0.6792\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.5607 - accuracy: 0.7083 - val_loss: 0.5760 - val_accuracy: 0.7170\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.5716 - accuracy: 0.7130 - val_loss: 0.5482 - val_accuracy: 0.7170\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.5397 - accuracy: 0.7176 - val_loss: 0.5198 - val_accuracy: 0.7547\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.5046 - accuracy: 0.7407 - val_loss: 0.4720 - val_accuracy: 0.8113\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.4146 - accuracy: 0.8056 - val_loss: 0.4892 - val_accuracy: 0.7925\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.4187 - accuracy: 0.8009 - val_loss: 0.5350 - val_accuracy: 0.7547\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.4584 - val_accuracy: 0.7925\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.5140 - accuracy: 0.7269 - val_loss: 0.4993 - val_accuracy: 0.7170\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.4726 - accuracy: 0.7407 - val_loss: 0.5091 - val_accuracy: 0.6981\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.4236 - accuracy: 0.8194 - val_loss: 0.5024 - val_accuracy: 0.7736\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.4212 - accuracy: 0.7824 - val_loss: 0.5522 - val_accuracy: 0.7925\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.3811 - accuracy: 0.8102 - val_loss: 0.5604 - val_accuracy: 0.7358\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.3945 - accuracy: 0.7917 - val_loss: 0.4902 - val_accuracy: 0.8302\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.3966 - accuracy: 0.7778 - val_loss: 0.4215 - val_accuracy: 0.8113\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.3386 - accuracy: 0.8472 - val_loss: 0.4938 - val_accuracy: 0.7736\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.2996 - accuracy: 0.8519 - val_loss: 0.4709 - val_accuracy: 0.8302\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.3508 - accuracy: 0.8565 - val_loss: 0.5270 - val_accuracy: 0.7925\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.3758 - accuracy: 0.8519 - val_loss: 0.4420 - val_accuracy: 0.7925\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.3291 - accuracy: 0.8472 - val_loss: 0.5374 - val_accuracy: 0.7736\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.3415 - accuracy: 0.8426 - val_loss: 0.4289 - val_accuracy: 0.7736\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.3395 - accuracy: 0.8472 - val_loss: 0.4838 - val_accuracy: 0.7736\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.3075 - accuracy: 0.8565 - val_loss: 0.4382 - val_accuracy: 0.7925\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.3415 - accuracy: 0.8056 - val_loss: 0.4425 - val_accuracy: 0.8113\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.3055 - accuracy: 0.8750 - val_loss: 0.5370 - val_accuracy: 0.8113\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_check.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True)\n",
    "history_check = model_check.fit(train_generator, validation_data = validation_generator, epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(model_check)\n",
    "model_names.append(\"Conv2D Check\")\n",
    "histories.append(history_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from generators to numpy arrays\n",
    "\n",
    "def generator_to_numpy(generator):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for _ in range(len(generator)):\n",
    "        img_batch, label_batch = next(generator)\n",
    "        images.extend(img_batch)\n",
    "        labels.extend(label_batch)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation data as numpy arrays\n",
    "X_train, y_train = generator_to_numpy(train_generator)\n",
    "X_val, y_val = generator_to_numpy(validation_generator)\n",
    "\n",
    "# Flatten images for logistic regression\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "history_logit = logistic_model.fit(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_model)\n",
    "model_names.append(\"Simple Logistic Regression\")\n",
    "histories.append(history_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_val_scaled = scaler.transform(X_val_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logistic_scaled = LogisticRegression(max_iter=2000, solver='lbfgs')\n",
    "history_logit_scaled = logistic_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_scaled)\n",
    "model_names.append(\"Scaled Logistic Regression\")\n",
    "histories.append(history_logit_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5185 - val_loss: 0.6927 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6924 - accuracy: 0.5926 - val_loss: 0.6920 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6918 - accuracy: 0.5926 - val_loss: 0.6913 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6912 - accuracy: 0.5926 - val_loss: 0.6906 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.5926 - val_loss: 0.6900 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6900 - accuracy: 0.5926 - val_loss: 0.6894 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6895 - accuracy: 0.5926 - val_loss: 0.6888 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6890 - accuracy: 0.5926 - val_loss: 0.6882 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6886 - accuracy: 0.5926 - val_loss: 0.6877 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6881 - accuracy: 0.5926 - val_loss: 0.6872 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.5926 - val_loss: 0.6866 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6871 - accuracy: 0.5926 - val_loss: 0.6861 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6867 - accuracy: 0.5926 - val_loss: 0.6856 - val_accuracy: 0.6038\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6863 - accuracy: 0.5926 - val_loss: 0.6851 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6859 - accuracy: 0.5926 - val_loss: 0.6847 - val_accuracy: 0.6038\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6855 - accuracy: 0.5926 - val_loss: 0.6842 - val_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6851 - accuracy: 0.5926 - val_loss: 0.6838 - val_accuracy: 0.6038\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6847 - accuracy: 0.5926 - val_loss: 0.6834 - val_accuracy: 0.6038\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6844 - accuracy: 0.5926 - val_loss: 0.6830 - val_accuracy: 0.6038\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6841 - accuracy: 0.5926 - val_loss: 0.6826 - val_accuracy: 0.6038\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6837 - accuracy: 0.5926 - val_loss: 0.6823 - val_accuracy: 0.6038\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.5926 - val_loss: 0.6820 - val_accuracy: 0.6038\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6832 - accuracy: 0.5926 - val_loss: 0.6817 - val_accuracy: 0.6038\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6829 - accuracy: 0.5926 - val_loss: 0.6813 - val_accuracy: 0.6038\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6826 - accuracy: 0.5926 - val_loss: 0.6810 - val_accuracy: 0.6038\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6824 - accuracy: 0.5926 - val_loss: 0.6807 - val_accuracy: 0.6038\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6822 - accuracy: 0.5926 - val_loss: 0.6804 - val_accuracy: 0.6038\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5926 - val_loss: 0.6801 - val_accuracy: 0.6038\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6816 - accuracy: 0.5926 - val_loss: 0.6799 - val_accuracy: 0.6038\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6814 - accuracy: 0.5926 - val_loss: 0.6796 - val_accuracy: 0.6038\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6812 - accuracy: 0.5926 - val_loss: 0.6794 - val_accuracy: 0.6038\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6810 - accuracy: 0.5926 - val_loss: 0.6791 - val_accuracy: 0.6038\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.5926 - val_loss: 0.6789 - val_accuracy: 0.6038\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6807 - accuracy: 0.5926 - val_loss: 0.6787 - val_accuracy: 0.6038\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6805 - accuracy: 0.5926 - val_loss: 0.6785 - val_accuracy: 0.6038\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6803 - accuracy: 0.5926 - val_loss: 0.6782 - val_accuracy: 0.6038\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6802 - accuracy: 0.5926 - val_loss: 0.6780 - val_accuracy: 0.6038\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6800 - accuracy: 0.5926 - val_loss: 0.6778 - val_accuracy: 0.6038\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.5926 - val_loss: 0.6776 - val_accuracy: 0.6038\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6796 - accuracy: 0.5926 - val_loss: 0.6774 - val_accuracy: 0.6038\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6795 - accuracy: 0.5926 - val_loss: 0.6773 - val_accuracy: 0.6038\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5926 - val_loss: 0.6771 - val_accuracy: 0.6038\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6792 - accuracy: 0.5926 - val_loss: 0.6769 - val_accuracy: 0.6038\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.5926 - val_loss: 0.6768 - val_accuracy: 0.6038\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6789 - accuracy: 0.5926 - val_loss: 0.6766 - val_accuracy: 0.6038\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5926 - val_loss: 0.6765 - val_accuracy: 0.6038\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5926 - val_loss: 0.6763 - val_accuracy: 0.6038\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.5926 - val_loss: 0.6762 - val_accuracy: 0.6038\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.5926 - val_loss: 0.6760 - val_accuracy: 0.6038\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6784 - accuracy: 0.5926 - val_loss: 0.6759 - val_accuracy: 0.6038\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6783 - accuracy: 0.5926 - val_loss: 0.6757 - val_accuracy: 0.6038\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6782 - accuracy: 0.5926 - val_loss: 0.6756 - val_accuracy: 0.6038\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6781 - accuracy: 0.5926 - val_loss: 0.6755 - val_accuracy: 0.6038\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6780 - accuracy: 0.5926 - val_loss: 0.6754 - val_accuracy: 0.6038\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6780 - accuracy: 0.5926 - val_loss: 0.6753 - val_accuracy: 0.6038\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6779 - accuracy: 0.5926 - val_loss: 0.6752 - val_accuracy: 0.6038\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6778 - accuracy: 0.5926 - val_loss: 0.6751 - val_accuracy: 0.6038\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6778 - accuracy: 0.5926 - val_loss: 0.6750 - val_accuracy: 0.6038\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6776 - accuracy: 0.5926 - val_loss: 0.6749 - val_accuracy: 0.6038\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6776 - accuracy: 0.5926 - val_loss: 0.6748 - val_accuracy: 0.6038\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6747 - val_accuracy: 0.6038\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6746 - val_accuracy: 0.6038\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.5926 - val_loss: 0.6745 - val_accuracy: 0.6038\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6745 - val_accuracy: 0.6038\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6744 - val_accuracy: 0.6038\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6772 - accuracy: 0.5926 - val_loss: 0.6743 - val_accuracy: 0.6038\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6742 - val_accuracy: 0.6038\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6742 - val_accuracy: 0.6038\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6741 - val_accuracy: 0.6038\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6740 - val_accuracy: 0.6038\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6740 - val_accuracy: 0.6038\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6739 - val_accuracy: 0.6038\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6739 - val_accuracy: 0.6038\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6738 - val_accuracy: 0.6038\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.6038\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.6038\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6727 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "x_train_sgd, x_val_sgd = X_train / 255.0, X_val / 255.0\n",
    "\n",
    "# Build model\n",
    "logistic_sgd = Sequential([\n",
    "    Flatten(input_shape = (64, 64, 3)),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "logistic_sgd.compile(optimizer = SGD(), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history_logistic_sgd = logistic_sgd.fit(x_train_sgd, y_train, validation_data=(x_val_sgd, y_val), epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_sgd)\n",
    "model_names.append(\"Logistic Regression - SGD\")\n",
    "histories.append(history_logistic_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "history_svm = svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(svm_model)\n",
    "model_names.append(\"Support Vector Machine\")\n",
    "histories.append(history_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 59ms/step - loss: 3.0296 - accuracy: 0.4722 - val_loss: 1.7624 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.0745 - accuracy: 0.5185 - val_loss: 0.6079 - val_accuracy: 0.7170\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.8176 - accuracy: 0.5972 - val_loss: 0.7571 - val_accuracy: 0.3962\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.7127 - accuracy: 0.5741 - val_loss: 0.7071 - val_accuracy: 0.5660\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.7922 - accuracy: 0.5370 - val_loss: 0.5849 - val_accuracy: 0.6981\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.6349 - accuracy: 0.6574 - val_loss: 0.5904 - val_accuracy: 0.7170\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6440 - accuracy: 0.6620 - val_loss: 0.7037 - val_accuracy: 0.6226\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.7285 - accuracy: 0.5926 - val_loss: 0.8008 - val_accuracy: 0.5849\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6773 - accuracy: 0.6389 - val_loss: 0.6711 - val_accuracy: 0.6604\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6128 - accuracy: 0.7037 - val_loss: 0.5819 - val_accuracy: 0.6792\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.5936 - accuracy: 0.6806 - val_loss: 0.6418 - val_accuracy: 0.6981\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6089 - accuracy: 0.7037 - val_loss: 0.5571 - val_accuracy: 0.7170\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.5748 - accuracy: 0.7269 - val_loss: 0.5605 - val_accuracy: 0.6981\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6472 - accuracy: 0.6667 - val_loss: 0.6352 - val_accuracy: 0.6226\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.5909 - accuracy: 0.7037 - val_loss: 0.5309 - val_accuracy: 0.7547\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.5979 - accuracy: 0.6898 - val_loss: 0.5750 - val_accuracy: 0.6792\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.5918 - accuracy: 0.6806 - val_loss: 0.5980 - val_accuracy: 0.7170\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.5778 - accuracy: 0.7176 - val_loss: 0.4597 - val_accuracy: 0.8113\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.6515 - accuracy: 0.6759 - val_loss: 0.6065 - val_accuracy: 0.6604\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.5942 - accuracy: 0.6667 - val_loss: 0.5409 - val_accuracy: 0.7547\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.5925 - accuracy: 0.7083 - val_loss: 0.5737 - val_accuracy: 0.6981\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.5761 - accuracy: 0.6898 - val_loss: 0.6024 - val_accuracy: 0.7358\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.7177 - accuracy: 0.6019 - val_loss: 0.6050 - val_accuracy: 0.6981\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6736 - accuracy: 0.6343 - val_loss: 0.6324 - val_accuracy: 0.6981\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.6611 - accuracy: 0.6528 - val_loss: 0.6982 - val_accuracy: 0.6604\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.6006 - accuracy: 0.7037 - val_loss: 0.5323 - val_accuracy: 0.7736\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.5548 - accuracy: 0.7083 - val_loss: 0.5751 - val_accuracy: 0.6792\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6205 - accuracy: 0.6991 - val_loss: 0.5387 - val_accuracy: 0.6415\n"
     ]
    }
   ],
   "source": [
    "model_mlp = Sequential([\n",
    "        Flatten(input_shape = (64, 64, 3)),\n",
    "        Dense(128, activation = 'relu'),\n",
    "        Dense(64, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "model_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_mlp = model_mlp.fit(train_generator, validation_data = validation_generator, epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(model_mlp)\n",
    "model_names.append(\"Multi Layer Perceptron\")\n",
    "histories.append(history_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 68ms/step - loss: 0.8107 - accuracy: 0.5417 - val_loss: 0.6792 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6826 - accuracy: 0.5926 - val_loss: 0.6677 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6732 - accuracy: 0.5926 - val_loss: 0.6611 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6468 - accuracy: 0.5926 - val_loss: 0.6397 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6294 - accuracy: 0.6019 - val_loss: 0.5752 - val_accuracy: 0.6792\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.5773 - accuracy: 0.6852 - val_loss: 0.5761 - val_accuracy: 0.7547\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.5948 - accuracy: 0.6944 - val_loss: 0.6087 - val_accuracy: 0.6792\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.5507 - accuracy: 0.7176 - val_loss: 0.5907 - val_accuracy: 0.6792\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.5596 - accuracy: 0.7176 - val_loss: 0.5441 - val_accuracy: 0.7547\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.5756 - accuracy: 0.7315 - val_loss: 0.5802 - val_accuracy: 0.7358\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.5624 - accuracy: 0.7176 - val_loss: 0.5253 - val_accuracy: 0.7358\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.5247 - accuracy: 0.7500 - val_loss: 0.5340 - val_accuracy: 0.8113\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.5107 - accuracy: 0.7407 - val_loss: 0.5293 - val_accuracy: 0.7925\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.4965 - accuracy: 0.7685 - val_loss: 0.5309 - val_accuracy: 0.7547\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.4566 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7547\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.4579 - accuracy: 0.7824 - val_loss: 0.5546 - val_accuracy: 0.7547\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.4985 - accuracy: 0.7963 - val_loss: 0.4915 - val_accuracy: 0.7736\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.4806 - accuracy: 0.7546 - val_loss: 0.4972 - val_accuracy: 0.7170\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.4865 - accuracy: 0.7639 - val_loss: 0.5027 - val_accuracy: 0.7358\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.4506 - accuracy: 0.7963 - val_loss: 0.4689 - val_accuracy: 0.8113\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.4661 - accuracy: 0.7778 - val_loss: 0.5150 - val_accuracy: 0.7547\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.4506 - accuracy: 0.7778 - val_loss: 0.4685 - val_accuracy: 0.7925\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.4497 - accuracy: 0.7824 - val_loss: 0.4317 - val_accuracy: 0.8302\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5002 - val_accuracy: 0.8113\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.4787 - accuracy: 0.7870 - val_loss: 0.4922 - val_accuracy: 0.7170\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.4490 - accuracy: 0.8056 - val_loss: 0.4694 - val_accuracy: 0.7925\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.4411 - accuracy: 0.7870 - val_loss: 0.4555 - val_accuracy: 0.7547\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.4140 - accuracy: 0.8194 - val_loss: 0.4409 - val_accuracy: 0.7736\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.4160 - accuracy: 0.8102 - val_loss: 0.4113 - val_accuracy: 0.8113\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.3664 - accuracy: 0.8426 - val_loss: 0.4171 - val_accuracy: 0.8113\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.3617 - accuracy: 0.8380 - val_loss: 0.4423 - val_accuracy: 0.7925\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.3553 - accuracy: 0.8426 - val_loss: 0.4453 - val_accuracy: 0.8113\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.4180 - accuracy: 0.8148 - val_loss: 0.5042 - val_accuracy: 0.7736\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.3643 - accuracy: 0.8287 - val_loss: 0.4200 - val_accuracy: 0.8302\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.3376 - accuracy: 0.8519 - val_loss: 0.4281 - val_accuracy: 0.8491\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.3567 - accuracy: 0.8426 - val_loss: 0.4396 - val_accuracy: 0.7547\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.2961 - accuracy: 0.8426 - val_loss: 0.4712 - val_accuracy: 0.7547\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.3345 - accuracy: 0.8380 - val_loss: 0.4008 - val_accuracy: 0.8491\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.2963 - accuracy: 0.8704 - val_loss: 0.4505 - val_accuracy: 0.7736\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.3104 - accuracy: 0.8704 - val_loss: 0.4063 - val_accuracy: 0.8113\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.2991 - accuracy: 0.8426 - val_loss: 0.4166 - val_accuracy: 0.8113\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.2926 - accuracy: 0.8796 - val_loss: 0.4186 - val_accuracy: 0.8113\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.3155 - accuracy: 0.8426 - val_loss: 0.4630 - val_accuracy: 0.7925\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.2911 - accuracy: 0.8796 - val_loss: 0.4655 - val_accuracy: 0.7547\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.2909 - accuracy: 0.8657 - val_loss: 0.4319 - val_accuracy: 0.8868\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.3020 - accuracy: 0.8611 - val_loss: 0.4454 - val_accuracy: 0.8491\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.3296 - accuracy: 0.8704 - val_loss: 0.5050 - val_accuracy: 0.7925\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.3100 - accuracy: 0.8611 - val_loss: 0.4149 - val_accuracy: 0.8302\n"
     ]
    }
   ],
   "source": [
    "lenet_model = Sequential([\n",
    "        Conv2D(6, (5, 5), activation = 'relu', padding = 'same', input_shape = (64, 64, 3)),\n",
    "        MaxPooling2D(pool_size = (2, 2)),\n",
    "        Conv2D(16, (5, 5), activation = 'relu'),\n",
    "        MaxPooling2D(pool_size = (2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(120, activation = 'relu'),\n",
    "        Dense(84, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "lenet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "lenet_history = lenet_model.fit(train_generator, validation_data = validation_generator, epochs = 100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(lenet_model)\n",
    "model_names.append(\"LeNet - 5\")\n",
    "histories.append(lenet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 6s 580ms/step - loss: 2.7009 - accuracy: 0.5417 - val_loss: 0.6824 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.6868 - accuracy: 0.5926 - val_loss: 0.6618 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.6733 - accuracy: 0.5926 - val_loss: 0.5761 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.6300 - accuracy: 0.5926 - val_loss: 0.5845 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.5360 - accuracy: 0.5926 - val_loss: 0.5040 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.6841 - accuracy: 0.6944 - val_loss: 0.6286 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.6705 - accuracy: 0.5139 - val_loss: 0.6706 - val_accuracy: 0.5849\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.5627 - accuracy: 0.5833 - val_loss: 0.4768 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5157 - accuracy: 0.7176 - val_loss: 0.4615 - val_accuracy: 0.7547\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.4969 - accuracy: 0.7315 - val_loss: 0.4412 - val_accuracy: 0.7736\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5005 - accuracy: 0.7407 - val_loss: 0.4894 - val_accuracy: 0.6981\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5193 - accuracy: 0.6944 - val_loss: 0.4598 - val_accuracy: 0.7170\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.4484 - accuracy: 0.7454 - val_loss: 0.4743 - val_accuracy: 0.7170\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.4648 - accuracy: 0.7546 - val_loss: 0.4406 - val_accuracy: 0.7170\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.3981 - accuracy: 0.7963 - val_loss: 0.4911 - val_accuracy: 0.7170\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.4328 - accuracy: 0.7593 - val_loss: 0.4474 - val_accuracy: 0.7358\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.4777 - accuracy: 0.7870 - val_loss: 0.5035 - val_accuracy: 0.6981\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.4923 - accuracy: 0.7222 - val_loss: 0.4821 - val_accuracy: 0.7170\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5011 - accuracy: 0.7269 - val_loss: 0.4928 - val_accuracy: 0.6792\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.4756 - accuracy: 0.7269 - val_loss: 0.4775 - val_accuracy: 0.6981\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.4189 - accuracy: 0.7870 - val_loss: 0.5006 - val_accuracy: 0.6792\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.4335 - accuracy: 0.7546 - val_loss: 0.4378 - val_accuracy: 0.7547\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.4797 - accuracy: 0.7361 - val_loss: 0.4833 - val_accuracy: 0.7170\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.4367 - accuracy: 0.7593 - val_loss: 0.4378 - val_accuracy: 0.7547\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4540 - val_accuracy: 0.7358\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.4888 - accuracy: 0.7269 - val_loss: 0.5140 - val_accuracy: 0.7170\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.4934 - accuracy: 0.7361 - val_loss: 0.4727 - val_accuracy: 0.7170\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.4581 - accuracy: 0.7361 - val_loss: 0.4927 - val_accuracy: 0.6981\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.4433 - accuracy: 0.7454 - val_loss: 0.4442 - val_accuracy: 0.7547\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.4412 - accuracy: 0.7546 - val_loss: 0.4437 - val_accuracy: 0.7358\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.4384 - accuracy: 0.7546 - val_loss: 0.4241 - val_accuracy: 0.7547\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.4115 - accuracy: 0.7824 - val_loss: 0.4043 - val_accuracy: 0.7925\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.4863 - accuracy: 0.8056 - val_loss: 0.4403 - val_accuracy: 0.7547\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.4693 - accuracy: 0.7269 - val_loss: 0.5099 - val_accuracy: 0.6792\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.4830 - accuracy: 0.7130 - val_loss: 0.4567 - val_accuracy: 0.7170\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.4621 - accuracy: 0.7454 - val_loss: 0.4524 - val_accuracy: 0.7358\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.4705 - accuracy: 0.7361 - val_loss: 0.4505 - val_accuracy: 0.7358\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.4367 - accuracy: 0.7593 - val_loss: 0.4476 - val_accuracy: 0.7358\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.4245 - accuracy: 0.7778 - val_loss: 0.4082 - val_accuracy: 0.7736\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.4681 - accuracy: 0.7870 - val_loss: 0.4601 - val_accuracy: 0.7170\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.4393 - accuracy: 0.7593 - val_loss: 0.4827 - val_accuracy: 0.7170\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.4318 - accuracy: 0.7593 - val_loss: 0.5925 - val_accuracy: 0.7358\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = Sequential([\n",
    "        Conv2D(96, (11, 11), activation = 'relu', strides = (4, 4), input_shape = (224, 224, 3)),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Conv2D(256, (5, 5), activation = 'relu', padding = 'same'),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Conv2D(384, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(384, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "alexnet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "alexnet_history = alexnet_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(alexnet_model)\n",
    "model_names.append(\"AlexNet\")\n",
    "histories.append(alexnet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 (Without Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 35s 3s/step - loss: 3.7155 - accuracy: 0.4722 - val_loss: 0.6947 - val_accuracy: 0.5094\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 408ms/step - loss: 0.7782 - accuracy: 0.5741 - val_loss: 0.6883 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.6815 - accuracy: 0.5602 - val_loss: 0.6947 - val_accuracy: 0.4340\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 4s 473ms/step - loss: 0.6898 - accuracy: 0.5417 - val_loss: 0.6886 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 4s 482ms/step - loss: 0.9112 - accuracy: 0.5556 - val_loss: 0.6840 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 468ms/step - loss: 0.6958 - accuracy: 0.5556 - val_loss: 0.6858 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 4s 479ms/step - loss: 0.6933 - accuracy: 0.5694 - val_loss: 0.6710 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 463ms/step - loss: 0.6838 - accuracy: 0.5880 - val_loss: 0.6754 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 4s 474ms/step - loss: 0.6834 - accuracy: 0.5880 - val_loss: 0.6719 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 4s 476ms/step - loss: 0.6814 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 4s 475ms/step - loss: 0.6776 - accuracy: 0.5972 - val_loss: 0.6718 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 473ms/step - loss: 0.6753 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 4s 471ms/step - loss: 0.6853 - accuracy: 0.5926 - val_loss: 0.6723 - val_accuracy: 0.6038\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 4s 494ms/step - loss: 0.6839 - accuracy: 0.5926 - val_loss: 0.6766 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 4s 492ms/step - loss: 0.6809 - accuracy: 0.5926 - val_loss: 0.6704 - val_accuracy: 0.6038\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 4s 466ms/step - loss: 0.6731 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 464ms/step - loss: 0.6887 - accuracy: 0.5880 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 471ms/step - loss: 0.6788 - accuracy: 0.5926 - val_loss: 0.6761 - val_accuracy: 0.6038\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 4s 480ms/step - loss: 0.6831 - accuracy: 0.5926 - val_loss: 0.6741 - val_accuracy: 0.6038\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 4s 469ms/step - loss: 0.6831 - accuracy: 0.5926 - val_loss: 0.6724 - val_accuracy: 0.6038\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 4s 474ms/step - loss: 0.6827 - accuracy: 0.5926 - val_loss: 0.6726 - val_accuracy: 0.6038\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 4s 476ms/step - loss: 0.6731 - accuracy: 0.5926 - val_loss: 0.6718 - val_accuracy: 0.6038\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 4s 473ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6712 - val_accuracy: 0.6038\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 4s 475ms/step - loss: 0.6729 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 4s 474ms/step - loss: 0.6759 - accuracy: 0.5926 - val_loss: 0.6709 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "# Load VGG16 model\n",
    "base_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Build model\n",
    "vgg_16_model = Sequential([\n",
    "    base_vgg16,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_16_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg16_history = vgg_16_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(vgg_16_model)\n",
    "model_names.append(\"VGG16\")\n",
    "histories.append(vgg16_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 (Without Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 5s 635ms/step - loss: 9.5842 - accuracy: 0.5556 - val_loss: 0.7196 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 0.7277 - accuracy: 0.5000 - val_loss: 0.6905 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 4s 543ms/step - loss: 0.7059 - accuracy: 0.5972 - val_loss: 0.7240 - val_accuracy: 0.3962\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 4s 553ms/step - loss: 0.7062 - accuracy: 0.5417 - val_loss: 0.6849 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 4s 551ms/step - loss: 0.6864 - accuracy: 0.5833 - val_loss: 0.6738 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.6945 - accuracy: 0.5880 - val_loss: 0.6795 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 4s 564ms/step - loss: 0.6872 - accuracy: 0.5926 - val_loss: 0.6811 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 552ms/step - loss: 0.6886 - accuracy: 0.5602 - val_loss: 0.6712 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 4s 546ms/step - loss: 0.6849 - accuracy: 0.5926 - val_loss: 0.6811 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 4s 540ms/step - loss: 0.6855 - accuracy: 0.5926 - val_loss: 0.6753 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 4s 543ms/step - loss: 0.6827 - accuracy: 0.5926 - val_loss: 0.6727 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 538ms/step - loss: 0.6794 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 4s 571ms/step - loss: 0.6833 - accuracy: 0.5926 - val_loss: 0.6776 - val_accuracy: 0.6038\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 4s 554ms/step - loss: 0.6827 - accuracy: 0.5926 - val_loss: 0.6749 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 4s 569ms/step - loss: 0.6758 - accuracy: 0.5926 - val_loss: 0.6710 - val_accuracy: 0.6038\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.6801 - accuracy: 0.5926 - val_loss: 0.6702 - val_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 528ms/step - loss: 0.6691 - accuracy: 0.5926 - val_loss: 0.6752 - val_accuracy: 0.6038\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 490ms/step - loss: 0.6932 - accuracy: 0.5833 - val_loss: 0.6769 - val_accuracy: 0.6038\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 0.6822 - accuracy: 0.5926 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 0.6776 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6719 - val_accuracy: 0.6038\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 4s 553ms/step - loss: 0.6809 - accuracy: 0.5926 - val_loss: 0.6742 - val_accuracy: 0.6038\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 4s 554ms/step - loss: 0.6802 - accuracy: 0.5926 - val_loss: 0.6726 - val_accuracy: 0.6038\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.6695 - accuracy: 0.5926 - val_loss: 0.6706 - val_accuracy: 0.6038\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.6832 - accuracy: 0.5926 - val_loss: 0.6716 - val_accuracy: 0.6038\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 0.6742 - accuracy: 0.5972 - val_loss: 0.6980 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "base_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Build model\n",
    "vgg_19_model = Sequential([\n",
    "    base_vgg19,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_19_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg19_history = vgg_19_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(vgg_19_model)\n",
    "model_names.append(\"VGG19\")\n",
    "histories.append(vgg19_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting resource exhaust error even with batch_size of 2\n",
    "\n",
    "# # Load VGG16 model\n",
    "# base_vgg16_2 = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "# # Build model\n",
    "# vgg_16_model_2 = Sequential([\n",
    "#     base_vgg16_2,\n",
    "#     Flatten(),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Compile model\n",
    "# vgg_16_model_2.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# vgg16_history_2 = vgg_16_model_2.fit(train_generator_224_8, validation_data = validation_generator_224_8, epochs = 100, \n",
    "#                                     callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(vgg_16_model_2)\n",
    "# model_names.append(\"VGG16_2\")\n",
    "# histories.append(vgg16_history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting resource exhaust error even with batch_size of 2\n",
    "\n",
    "# base_vgg19_2 = VGG19(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "# # Build model\n",
    "# vgg_19_model_2 = Sequential([\n",
    "#     base_vgg19_2,\n",
    "#     Flatten(),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Compile model\n",
    "# vgg_19_model_2.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# vgg19_history_2 = vgg_19_model_2.fit(train_generator_224_8, validation_data = validation_generator_224_8, epochs = 100, \n",
    "#                                     callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(vgg_19_model_2)\n",
    "# model_names.append(\"VGG19_2\")\n",
    "# histories.append(vgg19_history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogLe Net (Without Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 11s 831ms/step - loss: 10.5830 - accuracy: 0.5787 - val_loss: 8.7367 - val_accuracy: 0.6226\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 2s 283ms/step - loss: 1.3921 - accuracy: 0.7454 - val_loss: 155.7458 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 2s 282ms/step - loss: 0.5775 - accuracy: 0.7870 - val_loss: 77.2508 - val_accuracy: 0.3774\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 2s 280ms/step - loss: 0.3754 - accuracy: 0.8333 - val_loss: 68.7673 - val_accuracy: 0.5283\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 2s 283ms/step - loss: 0.3274 - accuracy: 0.8750 - val_loss: 777.4735 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 2s 284ms/step - loss: 0.4929 - accuracy: 0.8750 - val_loss: 1638.6511 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 2s 286ms/step - loss: 0.2226 - accuracy: 0.9259 - val_loss: 275.0490 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 2s 283ms/step - loss: 0.4506 - accuracy: 0.8889 - val_loss: 160.7144 - val_accuracy: 0.5283\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 2s 285ms/step - loss: 0.4947 - accuracy: 0.8519 - val_loss: 2118.8613 - val_accuracy: 0.4906\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 2s 281ms/step - loss: 0.2931 - accuracy: 0.8287 - val_loss: 59838.8477 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 2s 298ms/step - loss: 0.2840 - accuracy: 0.9167 - val_loss: 66109.3672 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "def create_inceptionv3_model(input_shape, num_classes):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "inceptionv3_model = create_inceptionv3_model(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# Train the model\n",
    "inceptionv3_history = inceptionv3_model.fit(\n",
    "    train_generator_224,\n",
    "    validation_data=validation_generator_224,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(inceptionv3_model)\n",
    "model_names.append(\"GoogLe Net\")\n",
    "histories.append(inceptionv3_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ### GoogLe Net (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource exhaust error, but it worked first time I ran it but over fitting\n",
    "\n",
    "# def create_inceptionv3_model_top(input_shape, num_classes):\n",
    "#     base_model = InceptionV3(weights='imagenet', include_top=True, input_shape=input_shape)\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         Flatten(),\n",
    "#         Dense(1024, activation='relu'),\n",
    "#         Dropout(0.5)\n",
    "#         Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# inceptionv3_model_top = create_inceptionv3_model_top(input_shape=(299, 299, 3), num_classes=1)\n",
    "\n",
    "# # Train the model\n",
    "# inceptionv3_history_top = inceptionv3_model_top.fit(\n",
    "#     train_generator_299,\n",
    "#     validation_data=validation_generator_299,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(inceptionv3_model_top)\n",
    "# model_names.append(\"GoogLe Net (With Top)\")\n",
    "# histories.append(inceptionv3_history_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource exhaust even with batch_size = 2\n",
    "\n",
    "# def create_resnet50_model(input_shape, num_classes):\n",
    "#     base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         Flatten(),\n",
    "#         Dense(1024, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# resnet50_model = create_resnet50_model(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# # Train the model\n",
    "# resnet50_history = resnet50_model.fit(\n",
    "#     train_generator_224_8,\n",
    "#     validation_data=validation_generator_224_8,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(resnet50_model)\n",
    "# model_names.append(\"ResNet-50\")\n",
    "# histories.append(resnet50_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-50 (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource exhaust even with batch_size = 2\n",
    "\n",
    "# def create_resnet50_model_top(input_shape, num_classes):\n",
    "#     base_model = ResNet50(weights='imagenet', include_top=True, input_shape=input_shape)\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         Flatten(),\n",
    "#         Dense(1024, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# resnet50_model_top = create_resnet50_model_top(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# # Train the model\n",
    "# resnet50_history_top = resnet50_model_top.fit(\n",
    "#     train_generator_224_8,\n",
    "#     validation_data=validation_generator_224_8,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(resnet50_model_top)\n",
    "# model_names.append(\"ResNet-50 (With Top)\")\n",
    "# histories.append(resnet50_history_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource exhaust even with batch_size = 2\n",
    "\n",
    "# def create_mobilenet_model(input_shape, num_classes):\n",
    "#     base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         Flatten(),\n",
    "#         Dense(1024, activation='relu'),\n",
    "#         Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# mobilenet_model = create_mobilenet_model(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# # Train the model\n",
    "# mobilenet_history = mobilenet_model.fit(\n",
    "#     train_generator_224_8,\n",
    "#     validation_data=validation_generator_224_8,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(mobilenet_model)\n",
    "# model_names.append(\"MobileNet\")\n",
    "# histories.append(mobilenet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource exhaust even with batch_size = 2\n",
    "\n",
    "# def create_mobilenet_model_top(input_shape, num_classes):\n",
    "#     base_model = MobileNet(weights='imagenet', include_top=True, input_shape=input_shape)\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         Flatten(),\n",
    "#         Dense(1024, activation='relu'),\n",
    "#         Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# mobilenet_model_top = create_mobilenet_model_top(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# # Train the model\n",
    "# mobilenet_history_top = mobilenet_model_top.fit(\n",
    "#     train_generator_224_8,\n",
    "#     validation_data=validation_generator_224_8,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(mobilenet_model_top)\n",
    "# model_names.append(\"MobileNet (With Top)\")\n",
    "# histories.append(mobilenet_history_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 14s 77ms/step - loss: 17.2525 - accuracy: 0.5648 - val_loss: 24.2041 - val_accuracy: 0.6226\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 7s 67ms/step - loss: 1.3516 - accuracy: 0.6481 - val_loss: 3.2305 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 7s 67ms/step - loss: 1.1980 - accuracy: 0.6991 - val_loss: 3.2063 - val_accuracy: 0.5660\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.8626 - accuracy: 0.6667 - val_loss: 0.8859 - val_accuracy: 0.7925\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.6661 - accuracy: 0.7269 - val_loss: 0.5156 - val_accuracy: 0.7547\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.3554 - accuracy: 0.8333 - val_loss: 0.5507 - val_accuracy: 0.8491\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.4471 - accuracy: 0.8194 - val_loss: 0.3364 - val_accuracy: 0.8679\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.3687 - accuracy: 0.8241 - val_loss: 0.4971 - val_accuracy: 0.8491\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.3039 - accuracy: 0.8611 - val_loss: 0.3405 - val_accuracy: 0.8302\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2435 - accuracy: 0.8843 - val_loss: 0.3716 - val_accuracy: 0.9057\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2612 - accuracy: 0.8935 - val_loss: 0.3656 - val_accuracy: 0.8679\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.1862 - accuracy: 0.9259 - val_loss: 0.2447 - val_accuracy: 0.8868\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2369 - accuracy: 0.8935 - val_loss: 0.3016 - val_accuracy: 0.9245\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2626 - accuracy: 0.8935 - val_loss: 0.7969 - val_accuracy: 0.7925\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 7s 64ms/step - loss: 0.3328 - accuracy: 0.8611 - val_loss: 0.8927 - val_accuracy: 0.7358\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2932 - accuracy: 0.8657 - val_loss: 0.2442 - val_accuracy: 0.8868\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.1885 - accuracy: 0.9120 - val_loss: 0.4154 - val_accuracy: 0.8302\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2184 - accuracy: 0.9213 - val_loss: 0.2849 - val_accuracy: 0.8491\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2192 - accuracy: 0.9074 - val_loss: 0.2906 - val_accuracy: 0.8679\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.1411 - accuracy: 0.9537 - val_loss: 0.2952 - val_accuracy: 0.9057\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2434 - accuracy: 0.9167 - val_loss: 0.3317 - val_accuracy: 0.8491\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2285 - accuracy: 0.9306 - val_loss: 0.7057 - val_accuracy: 0.7358\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.1783 - accuracy: 0.9398 - val_loss: 0.1643 - val_accuracy: 0.9245\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.1800 - accuracy: 0.9352 - val_loss: 0.1787 - val_accuracy: 0.9434\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.1748 - accuracy: 0.9537 - val_loss: 0.3808 - val_accuracy: 0.8868\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2352 - accuracy: 0.9120 - val_loss: 0.3530 - val_accuracy: 0.8679\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.3439 - accuracy: 0.8704 - val_loss: 0.7009 - val_accuracy: 0.7736\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 7s 64ms/step - loss: 0.2062 - accuracy: 0.9259 - val_loss: 1.9056 - val_accuracy: 0.7925\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2080 - accuracy: 0.9120 - val_loss: 0.6242 - val_accuracy: 0.8491\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.2880 - accuracy: 0.9074 - val_loss: 0.3184 - val_accuracy: 0.8491\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.1412 - accuracy: 0.9444 - val_loss: 0.2973 - val_accuracy: 0.8868\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.1179 - accuracy: 0.9537 - val_loss: 0.5549 - val_accuracy: 0.8868\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.3472 - accuracy: 0.8750 - val_loss: 0.3354 - val_accuracy: 0.8679\n"
     ]
    }
   ],
   "source": [
    "def create_densenet_model(input_shape, num_classes):\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "densenet_model = create_densenet_model(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# Train the model\n",
    "densenet_history = densenet_model.fit(\n",
    "    train_generator_224_8,\n",
    "    validation_data=validation_generator_224_8,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(densenet_model)\n",
    "model_names.append(\"DenseNet\")\n",
    "histories.append(densenet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
      "33188688/33188688 [==============================] - 58s 2us/step\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 13s 68ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6761 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 6s 58ms/step - loss: 0.6591 - accuracy: 0.6019 - val_loss: 0.6547 - val_accuracy: 0.6226\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 6s 59ms/step - loss: 0.6082 - accuracy: 0.7037 - val_loss: 0.7573 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 6s 59ms/step - loss: 0.6639 - accuracy: 0.6389 - val_loss: 0.6763 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 6s 59ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 5s 44ms/step - loss: 0.6791 - accuracy: 0.5926 - val_loss: 0.6722 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 4s 41ms/step - loss: 0.6829 - accuracy: 0.5926 - val_loss: 0.6748 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 4s 41ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6781 - val_accuracy: 0.5849\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 4s 41ms/step - loss: 0.6780 - accuracy: 0.5926 - val_loss: 0.6791 - val_accuracy: 0.5849\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 4s 40ms/step - loss: 0.6792 - accuracy: 0.5926 - val_loss: 0.6790 - val_accuracy: 0.5849\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 5s 43ms/step - loss: 0.6856 - accuracy: 0.5926 - val_loss: 0.6763 - val_accuracy: 0.5849\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 6s 60ms/step - loss: 0.6792 - accuracy: 0.5926 - val_loss: 0.6774 - val_accuracy: 0.5849\n"
     ]
    }
   ],
   "source": [
    "def create_densenet_model_top(input_shape, num_classes):\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=True, input_shape=input_shape)\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "densenet_model_top = create_densenet_model_top(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# Train the model\n",
    "densenet_history_top = densenet_model_top.fit(\n",
    "    train_generator_224_8,\n",
    "    validation_data=validation_generator_224_8,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(densenet_model_top)\n",
    "model_names.append(\"DenseNet (With Top\")\n",
    "histories.append(densenet_history_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource exhaust even with batch_size = 2\n",
    "\n",
    "# def create_efficientnet_model(input_shape, num_classes):\n",
    "#     base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         Flatten(),\n",
    "#         Dense(1024, activation='relu'),\n",
    "#         Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# efficientnet_model = create_efficientnet_model(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# # Train the model\n",
    "# efficientnet_history = efficientnet_model.fit(\n",
    "#     train_generator_224_8,\n",
    "#     validation_data=validation_generator_224_8,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(efficientnet_model)\n",
    "# model_names.append(\"EfficientNet\")\n",
    "# histories.append(efficientnet_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EfficientNet (With Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource exhaust even with batch_size = 2\n",
    "\n",
    "# def create_efficientnet_model_top(input_shape, num_classes):\n",
    "#     base_model = EfficientNetB0(weights='imagenet', include_top=True, input_shape=input_shape)\n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         Flatten(),\n",
    "#         Dense(1024, activation='relu'),\n",
    "#         Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# efficientnet_model_top = create_efficientnet_model_top(input_shape=(224, 224, 3), num_classes=1)\n",
    "\n",
    "# # Train the model\n",
    "# efficientnet_history_top = efficientnet_model_top.fit(\n",
    "#     train_generator_224_8,\n",
    "#     validation_data=validation_generator_224_8,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.append(efficientnet_model_top)\n",
    "# model_names.append(\"EfficientNet (With Top\")\n",
    "# histories.append(efficientnet_history_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm1S5n-jo9PU"
   },
   "source": [
    "#### Evaluating the neural netwroks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate a model and return metrics\n",
    "def evaluate_model(model, validation_generator):\n",
    "    # Evaluate the model on the validation data\n",
    "    val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    val_steps = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "    predictions = model.predict(validation_generator, steps=val_steps)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = validation_generator.classes\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(true_classes, predicted_classes, target_names=validation_generator.class_indices.keys(), output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': val_accuracy,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "\n",
    "# Function to plot validation loss and accuracy\n",
    "def plot_metrics(histories, model_names):\n",
    "    \"\"\"\n",
    "    Plot validation loss and accuracy for multiple models.\n",
    "\n",
    "    Args:\n",
    "    histories (list): List of history objects for each model.\n",
    "    model_names (list): List of model names for plotting legend.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot validation loss for all models\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history, name in zip(histories, model_names):\n",
    "        plt.plot(history.history['val_loss'], label=f'Validation Loss ({name})')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation accuracy for all models\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history, name in zip(histories, model_names):\n",
    "        plt.plot(history.history['val_accuracy'], label=f'Validation Accuracy ({name})')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix ({model_name})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[104], line 41\u001b[0m, in \u001b[0;36mplot_metrics\u001b[1;34m(histories, model_names)\u001b[0m\n\u001b[0;32m     39\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m history, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(histories, model_names):\n\u001b[1;32m---> 41\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(histories, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator_224\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[104], line 4\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, validation_generator)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, validation_generator):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Evaluate the model on the validation data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m(validation_generator, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Predict on validation data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     val_steps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil(validation_generator\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m validation_generator\u001b[38;5;241m.\u001b[39mbatch_size)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "evaluate_model(models, validation_generator_224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_confusion_matrix(\u001b[43mcm\u001b[49m, class_names, model_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, class_names, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(histories, model_names):\n",
    "    \"\"\"\n",
    "    Plot validation loss and accuracy for multiple Keras models.\n",
    "\n",
    "    Args:\n",
    "    histories (list): List of history objects for each Keras model.\n",
    "    model_names (list): List of model names for plotting legend.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot validation loss for all models\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history, name in zip(histories, model_names):\n",
    "        plt.plot(history.history['val_loss'], label=f'Validation Loss ({name})')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation accuracy for all models\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history, name in zip(histories, model_names):\n",
    "        plt.plot(history.history['val_accuracy'], label=f'Validation Accuracy ({name})')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict, model_names):\n",
    "    \"\"\"\n",
    "    Plot metrics for multiple models.\n",
    "\n",
    "    Args:\n",
    "    metrics_dict (dict): Dictionary where keys are model names and values are dictionaries with 'val_loss' and 'val_accuracy'.\n",
    "    model_names (list): List of model names for plotting legend.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot validation loss for all models\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for name in model_names:\n",
    "        metrics = metrics_dict.get(name, {})\n",
    "        plt.plot(metrics.get('epochs', []), metrics.get('val_loss', []), label=f'Validation Loss ({name})')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot validation accuracy for all models\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for name in model_names:\n",
    "        metrics = metrics_dict.get(name, {})\n",
    "        plt.plot(metrics.get('epochs', []), metrics.get('val_accuracy', []), label=f'Validation Accuracy ({name})')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, validation_generator):\n",
    "    results = {}\n",
    "    for model in models:\n",
    "        # Evaluate the model on the validation data\n",
    "        val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "        \n",
    "        # Predict on validation data\n",
    "        val_steps = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "        predictions = model.predict(validation_generator, steps=val_steps)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        # Get true labels\n",
    "        true_classes = validation_generator.classes\n",
    "        \n",
    "        # Generate confusion matrix\n",
    "        cm = confusion_matrix(true_classes, predicted_classes)\n",
    "        \n",
    "        # Generate classification report\n",
    "        class_report = classification_report(true_classes, predicted_classes, target_names=validation_generator.class_indices.keys(), output_dict=True)\n",
    "        \n",
    "        results[model] = {\n",
    "            'loss': val_loss,\n",
    "            'accuracy': val_accuracy,\n",
    "            'confusion_matrix': cm,\n",
    "            'classification_report': class_report\n",
    "        }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metrics \u001b[38;5;129;01min\u001b[39;00m histories:\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[115], line 3\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(cm, class_names, model_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_confusion_matrix\u001b[39m(cm, class_names, model_name):\n\u001b[0;32m      2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m     \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Label\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue Label\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\seaborn\\matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\seaborn\\matrix.py:110\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[1;32m--> 110\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Validate the mask and convert to DataFrame\u001b[39;00m\n\u001b[0;32m    113\u001b[0m mask \u001b[38;5;241m=\u001b[39m _matrix_mask(data, mask)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\frame.py:758\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    747\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    748\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    749\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    755\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    756\u001b[0m         )\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 758\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:315\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    309\u001b[0m     _copy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    310\u001b[0m         copy_on_sanitize\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, dtype))\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    313\u001b[0m     )\n\u001b[0;32m    314\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, copy\u001b[38;5;241m=\u001b[39m_copy)\n\u001b[1;32m--> 315\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     values \u001b[38;5;241m=\u001b[39m _prep_ndarraylike(values, copy\u001b[38;5;241m=\u001b[39mcopy_on_sanitize)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:570\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    568\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 570\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=()"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, class_names, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix ({model_name})')\n",
    "    plt.show()\n",
    "\n",
    "for metrics in histories:\n",
    "    plot_confusion_matrix(metrics, class_names, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
