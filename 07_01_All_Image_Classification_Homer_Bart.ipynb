{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7znwBf0O6tpE"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import zipfile\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "dVfbaWDe8htY",
    "outputId": "998eef1f-4222-47d1-8f7f-51554c345742"
   },
   "outputs": [],
   "source": [
    "# path='/content/homer_bart_2.zip'\n",
    "\n",
    "# zip_obect=zipfile.ZipFile(file=path,mode='r')\n",
    "# zip_obect.extractall('./')\n",
    "# zip_obect.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = []\n",
    "histories = []\n",
    "\n",
    "# Function to evaluate a model and return metrics\n",
    "def evaluate_model(model, validation_generator):\n",
    "    # Evaluate the model on the validation data\n",
    "    val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    val_steps = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "    predictions = model.predict(validation_generator, steps=val_steps)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = validation_generator.classes\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(true_classes, predicted_classes, target_names=validation_generator.class_indices.keys(), output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': val_accuracy,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "\n",
    "# Function to plot validation loss and accuracy\n",
    "def plot_metrics(history, model_name):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['val_loss'], label=f'Validation Loss ({model_name})')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['val_accuracy'], label=f'Validation Accuracy ({model_name})')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix ({model_name})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHYWcwOTfIMP"
   },
   "source": [
    "#### Preprocessing on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 216 images belonging to 2 classes.\n",
      "Found 53 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "(64, 64, 3)\n",
      "{'bart': 0, 'homer': 1}\n",
      "{'bart': 0, 'homer': 1}\n",
      "{}\n",
      "(224, 224, 3)\n",
      "{'bart': 0, 'homer': 1}\n",
      "{'bart': 0, 'homer': 1}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your dataset\n",
    "dataset_path = 'homer_bart_1'\n",
    "\n",
    "# Create an ImageDataGenerator for training with data augmentation and validation split\n",
    "datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 20, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, validation_split = 0.2)\n",
    "\n",
    "# Load training data with augmentation\n",
    "train_generator = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = datagen.flow_from_directory(dataset_path, target_size = (64, 64), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Load training data with augmentation\n",
    "train_generator_224 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 32, class_mode = 'binary', \n",
    "                                              subset = 'training', seed = 123)\n",
    "\n",
    "# Load validation data\n",
    "validation_generator_224 = datagen.flow_from_directory(dataset_path, target_size = (224, 224), batch_size = 32, class_mode = 'binary', \n",
    "                                                   subset = 'validation', seed = 123)\n",
    "\n",
    "# Create a separate ImageDataGenerator for test data (only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Define the path to your test dataset\n",
    "test_dataset_path = 'test_dataset'\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(test_dataset_path, target_size = (64, 64), batch_size = 1, class_mode = 'binary')\n",
    "test_generator_244 = test_datagen.flow_from_directory(test_dataset_path, target_size = (224, 224), batch_size = 1, class_mode = 'binary')\n",
    "\n",
    "# Print class indices\n",
    "print(\"(64, 64, 3)\")\n",
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)\n",
    "\n",
    "print(\"(224, 224, 3)\")\n",
    "print(train_generator_224.class_indices)\n",
    "print(validation_generator_224.class_indices)\n",
    "print(test_generator_244.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSqnbI1VjU5J"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D Model (Checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EccXSMwHi4RI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 683,329\n",
      "Trainable params: 683,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model_check = Sequential([\n",
    "    layers.InputLayer(input_shape = (64, 64, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(1, activation = 'sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model_check.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG-9aj9RknrC",
    "outputId": "f638a7c7-3f2c-4e78-81d0-4fea757c475b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 5s 103ms/step - loss: 0.7210 - accuracy: 0.4954 - val_loss: 0.6723 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6634 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6512 - accuracy: 0.5926 - val_loss: 0.6242 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.6344 - accuracy: 0.5880 - val_loss: 0.6315 - val_accuracy: 0.7736\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.5927 - accuracy: 0.7361 - val_loss: 0.6399 - val_accuracy: 0.6415\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.6057 - accuracy: 0.6991 - val_loss: 0.6344 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.5947 - accuracy: 0.6852 - val_loss: 0.5561 - val_accuracy: 0.6226\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.5543 - accuracy: 0.6944 - val_loss: 0.5247 - val_accuracy: 0.7925\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.5242 - accuracy: 0.7639 - val_loss: 0.4892 - val_accuracy: 0.7925\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4081 - val_accuracy: 0.8302\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.4351 - accuracy: 0.7731 - val_loss: 0.4617 - val_accuracy: 0.7547\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.4098 - accuracy: 0.8056 - val_loss: 0.4067 - val_accuracy: 0.7925\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.3702 - accuracy: 0.8241 - val_loss: 0.4655 - val_accuracy: 0.7547\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.3983 - accuracy: 0.7963 - val_loss: 0.4668 - val_accuracy: 0.7358\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.3645 - accuracy: 0.8102 - val_loss: 0.4584 - val_accuracy: 0.7925\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.3576 - accuracy: 0.8380 - val_loss: 0.4532 - val_accuracy: 0.7547\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.3971 - accuracy: 0.8148 - val_loss: 0.3790 - val_accuracy: 0.8113\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.3308 - accuracy: 0.8750 - val_loss: 0.3695 - val_accuracy: 0.8113\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.3239 - accuracy: 0.8241 - val_loss: 0.3765 - val_accuracy: 0.8491\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.3061 - accuracy: 0.8796 - val_loss: 0.3404 - val_accuracy: 0.8302\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.2783 - accuracy: 0.8843 - val_loss: 0.3524 - val_accuracy: 0.7547\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.2361 - accuracy: 0.8935 - val_loss: 0.3766 - val_accuracy: 0.7925\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.2277 - accuracy: 0.8889 - val_loss: 0.4236 - val_accuracy: 0.8302\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.3411 - accuracy: 0.8241 - val_loss: 0.3545 - val_accuracy: 0.8113\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.2705 - accuracy: 0.8889 - val_loss: 0.3544 - val_accuracy: 0.8679\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.2890 - accuracy: 0.8611 - val_loss: 0.3323 - val_accuracy: 0.7925\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.2360 - accuracy: 0.9074 - val_loss: 0.3358 - val_accuracy: 0.8302\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.2344 - accuracy: 0.9167 - val_loss: 0.4170 - val_accuracy: 0.8679\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.2130 - accuracy: 0.9028 - val_loss: 0.4254 - val_accuracy: 0.8302\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.2978 - accuracy: 0.8843 - val_loss: 0.4019 - val_accuracy: 0.8113\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.3114 - accuracy: 0.8889 - val_loss: 0.3871 - val_accuracy: 0.8491\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.2775 - accuracy: 0.8704 - val_loss: 0.3175 - val_accuracy: 0.8868\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.2591 - accuracy: 0.8935 - val_loss: 0.2959 - val_accuracy: 0.8679\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.1944 - accuracy: 0.9444 - val_loss: 0.3131 - val_accuracy: 0.8679\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.1945 - accuracy: 0.8981 - val_loss: 0.3616 - val_accuracy: 0.8679\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.1979 - accuracy: 0.9259 - val_loss: 0.2619 - val_accuracy: 0.8868\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.2131 - accuracy: 0.8981 - val_loss: 0.3399 - val_accuracy: 0.8491\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.2203 - accuracy: 0.9028 - val_loss: 0.3455 - val_accuracy: 0.8302\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.1707 - accuracy: 0.9398 - val_loss: 0.4189 - val_accuracy: 0.8679\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.1683 - accuracy: 0.9352 - val_loss: 0.4369 - val_accuracy: 0.8302\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.1961 - accuracy: 0.9074 - val_loss: 0.3860 - val_accuracy: 0.8491\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.1983 - accuracy: 0.9167 - val_loss: 0.3469 - val_accuracy: 0.8868\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.1817 - accuracy: 0.9306 - val_loss: 0.3867 - val_accuracy: 0.8302\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.1723 - accuracy: 0.9120 - val_loss: 0.2501 - val_accuracy: 0.8679\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.1330 - accuracy: 0.9491 - val_loss: 0.3839 - val_accuracy: 0.8679\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.1706 - accuracy: 0.9491 - val_loss: 0.3126 - val_accuracy: 0.8491\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.2034 - accuracy: 0.9120 - val_loss: 0.3639 - val_accuracy: 0.7925\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.1989 - accuracy: 0.8935 - val_loss: 0.4425 - val_accuracy: 0.8679\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.1735 - accuracy: 0.9259 - val_loss: 0.4004 - val_accuracy: 0.8302\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.1576 - accuracy: 0.9537 - val_loss: 0.3317 - val_accuracy: 0.8868\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.1296 - accuracy: 0.9537 - val_loss: 0.2908 - val_accuracy: 0.8679\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.1316 - accuracy: 0.9352 - val_loss: 0.4065 - val_accuracy: 0.8491\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.1460 - accuracy: 0.9491 - val_loss: 0.3292 - val_accuracy: 0.8868\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.1410 - accuracy: 0.9398 - val_loss: 0.3500 - val_accuracy: 0.8491\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_check.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True)\n",
    "history_check = model_check.fit(train_generator, validation_data = validation_generator, epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(model_check)\n",
    "model_names.append(\"Conv2D Check\")\n",
    "histories.append(history_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from generators to numpy arrays\n",
    "\n",
    "def generator_to_numpy(generator):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for _ in range(len(generator)):\n",
    "        img_batch, label_batch = next(generator)\n",
    "        images.extend(img_batch)\n",
    "        labels.extend(label_batch)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation data as numpy arrays\n",
    "X_train, y_train = generator_to_numpy(train_generator)\n",
    "X_val, y_val = generator_to_numpy(validation_generator)\n",
    "\n",
    "# Flatten images for logistic regression\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "history_logit = logistic_model.fit(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_model)\n",
    "model_names.append(\"Simple Logistic Regression\")\n",
    "histories.append(history_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_val_scaled = scaler.transform(X_val_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logistic_scaled = LogisticRegression(max_iter=2000, solver='lbfgs')\n",
    "history_logit_scaled = logistic_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_scaled)\n",
    "model_names.append(\"Scaled Logistic Regression\")\n",
    "histories.append(history_logit_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6929 - accuracy: 0.5278 - val_loss: 0.6925 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5926 - val_loss: 0.6918 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6917 - accuracy: 0.5926 - val_loss: 0.6912 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6911 - accuracy: 0.5926 - val_loss: 0.6905 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.5926 - val_loss: 0.6899 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6900 - accuracy: 0.5926 - val_loss: 0.6893 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6894 - accuracy: 0.5926 - val_loss: 0.6887 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6889 - accuracy: 0.5926 - val_loss: 0.6881 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6884 - accuracy: 0.5926 - val_loss: 0.6876 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6880 - accuracy: 0.5926 - val_loss: 0.6871 - val_accuracy: 0.6038\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6875 - accuracy: 0.5926 - val_loss: 0.6866 - val_accuracy: 0.6038\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.5926 - val_loss: 0.6861 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6866 - accuracy: 0.5926 - val_loss: 0.6856 - val_accuracy: 0.6038\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6862 - accuracy: 0.5926 - val_loss: 0.6851 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6858 - accuracy: 0.5926 - val_loss: 0.6847 - val_accuracy: 0.6038\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6854 - accuracy: 0.5926 - val_loss: 0.6842 - val_accuracy: 0.6038\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6850 - accuracy: 0.5926 - val_loss: 0.6838 - val_accuracy: 0.6038\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6847 - accuracy: 0.5926 - val_loss: 0.6834 - val_accuracy: 0.6038\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.5926 - val_loss: 0.6830 - val_accuracy: 0.6038\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6840 - accuracy: 0.5926 - val_loss: 0.6827 - val_accuracy: 0.6038\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6837 - accuracy: 0.5926 - val_loss: 0.6823 - val_accuracy: 0.6038\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6834 - accuracy: 0.5926 - val_loss: 0.6820 - val_accuracy: 0.6038\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6831 - accuracy: 0.5926 - val_loss: 0.6817 - val_accuracy: 0.6038\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6829 - accuracy: 0.5926 - val_loss: 0.6813 - val_accuracy: 0.6038\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6825 - accuracy: 0.5926 - val_loss: 0.6810 - val_accuracy: 0.6038\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6823 - accuracy: 0.5926 - val_loss: 0.6807 - val_accuracy: 0.6038\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6821 - accuracy: 0.5926 - val_loss: 0.6804 - val_accuracy: 0.6038\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6818 - accuracy: 0.5926 - val_loss: 0.6802 - val_accuracy: 0.6038\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6817 - accuracy: 0.5926 - val_loss: 0.6799 - val_accuracy: 0.6038\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6813 - accuracy: 0.5926 - val_loss: 0.6796 - val_accuracy: 0.6038\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6811 - accuracy: 0.5926 - val_loss: 0.6794 - val_accuracy: 0.6038\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6810 - accuracy: 0.5926 - val_loss: 0.6791 - val_accuracy: 0.6038\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.5926 - val_loss: 0.6789 - val_accuracy: 0.6038\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6806 - accuracy: 0.5926 - val_loss: 0.6787 - val_accuracy: 0.6038\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6804 - accuracy: 0.5926 - val_loss: 0.6785 - val_accuracy: 0.6038\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6802 - accuracy: 0.5926 - val_loss: 0.6783 - val_accuracy: 0.6038\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6800 - accuracy: 0.5926 - val_loss: 0.6781 - val_accuracy: 0.6038\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6799 - accuracy: 0.5926 - val_loss: 0.6778 - val_accuracy: 0.6038\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6797 - accuracy: 0.5926 - val_loss: 0.6777 - val_accuracy: 0.6038\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6795 - accuracy: 0.5926 - val_loss: 0.6775 - val_accuracy: 0.6038\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5926 - val_loss: 0.6773 - val_accuracy: 0.6038\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.5926 - val_loss: 0.6771 - val_accuracy: 0.6038\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6791 - accuracy: 0.5926 - val_loss: 0.6770 - val_accuracy: 0.6038\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6790 - accuracy: 0.5926 - val_loss: 0.6768 - val_accuracy: 0.6038\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6788 - accuracy: 0.5926 - val_loss: 0.6766 - val_accuracy: 0.6038\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6787 - accuracy: 0.5926 - val_loss: 0.6765 - val_accuracy: 0.6038\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6786 - accuracy: 0.5926 - val_loss: 0.6763 - val_accuracy: 0.6038\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6785 - accuracy: 0.5926 - val_loss: 0.6762 - val_accuracy: 0.6038\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6784 - accuracy: 0.5926 - val_loss: 0.6761 - val_accuracy: 0.6038\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6783 - accuracy: 0.5926 - val_loss: 0.6760 - val_accuracy: 0.6038\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5926 - val_loss: 0.6758 - val_accuracy: 0.6038\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6781 - accuracy: 0.5926 - val_loss: 0.6757 - val_accuracy: 0.6038\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6781 - accuracy: 0.5926 - val_loss: 0.6756 - val_accuracy: 0.6038\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6779 - accuracy: 0.5926 - val_loss: 0.6755 - val_accuracy: 0.6038\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6779 - accuracy: 0.5926 - val_loss: 0.6754 - val_accuracy: 0.6038\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6778 - accuracy: 0.5926 - val_loss: 0.6753 - val_accuracy: 0.6038\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6777 - accuracy: 0.5926 - val_loss: 0.6752 - val_accuracy: 0.6038\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6776 - accuracy: 0.5926 - val_loss: 0.6751 - val_accuracy: 0.6038\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6750 - val_accuracy: 0.6038\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6775 - accuracy: 0.5926 - val_loss: 0.6749 - val_accuracy: 0.6038\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.5926 - val_loss: 0.6748 - val_accuracy: 0.6038\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6747 - val_accuracy: 0.6038\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6773 - accuracy: 0.5926 - val_loss: 0.6746 - val_accuracy: 0.6038\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6772 - accuracy: 0.5926 - val_loss: 0.6746 - val_accuracy: 0.6038\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6745 - val_accuracy: 0.6038\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6771 - accuracy: 0.5926 - val_loss: 0.6744 - val_accuracy: 0.6038\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6770 - accuracy: 0.5926 - val_loss: 0.6743 - val_accuracy: 0.6038\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6742 - val_accuracy: 0.6038\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6742 - val_accuracy: 0.6038\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.5926 - val_loss: 0.6741 - val_accuracy: 0.6038\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6740 - val_accuracy: 0.6038\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6768 - accuracy: 0.5926 - val_loss: 0.6740 - val_accuracy: 0.6038\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6739 - val_accuracy: 0.6038\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.5926 - val_loss: 0.6739 - val_accuracy: 0.6038\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6738 - val_accuracy: 0.6038\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6766 - accuracy: 0.5926 - val_loss: 0.6737 - val_accuracy: 0.6038\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.6038\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6765 - accuracy: 0.5926 - val_loss: 0.6736 - val_accuracy: 0.6038\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6764 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6763 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6732 - val_accuracy: 0.6038\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6760 - accuracy: 0.5926 - val_loss: 0.6730 - val_accuracy: 0.6038\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6761 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6760 - accuracy: 0.5926 - val_loss: 0.6729 - val_accuracy: 0.6038\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6760 - accuracy: 0.5926 - val_loss: 0.6728 - val_accuracy: 0.6038\n"
     ]
    }
   ],
   "source": [
    "x_train_sgd, x_val_sgd = X_train / 255.0, X_val / 255.0\n",
    "\n",
    "# Build model\n",
    "logistic_sgd = Sequential([\n",
    "    Flatten(input_shape = (64, 64, 3)),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "logistic_sgd.compile(optimizer = SGD(), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history_logistic_sgd = logistic_sgd.fit(x_train_sgd, y_train, validation_data=(x_val_sgd, y_val), epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(logistic_sgd)\n",
    "model_names.append(\"Logistic Regression - SGD\")\n",
    "histories.append(history_logistic_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "history_svm = svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(svm_model)\n",
    "model_names.append(\"Support Vector Machine\")\n",
    "histories.append(history_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 61ms/step - loss: 3.2071 - accuracy: 0.5185 - val_loss: 2.8259 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 1.5088 - accuracy: 0.5556 - val_loss: 0.5890 - val_accuracy: 0.6792\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 1.0118 - accuracy: 0.5324 - val_loss: 1.0155 - val_accuracy: 0.4340\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.8333 - accuracy: 0.5139 - val_loss: 0.5267 - val_accuracy: 0.7358\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6014 - accuracy: 0.7037 - val_loss: 0.5792 - val_accuracy: 0.6792\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.6209 - accuracy: 0.7083 - val_loss: 0.5965 - val_accuracy: 0.7358\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6755 - accuracy: 0.6620 - val_loss: 0.8452 - val_accuracy: 0.5283\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.8312 - accuracy: 0.5880 - val_loss: 0.6473 - val_accuracy: 0.6981\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6212 - accuracy: 0.7037 - val_loss: 0.5906 - val_accuracy: 0.7358\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6779 - accuracy: 0.6759 - val_loss: 0.7338 - val_accuracy: 0.4906\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6609 - accuracy: 0.6713 - val_loss: 0.5404 - val_accuracy: 0.6981\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6450 - accuracy: 0.6343 - val_loss: 0.6445 - val_accuracy: 0.7358\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.7057 - accuracy: 0.6528 - val_loss: 0.5703 - val_accuracy: 0.7547\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.8576 - accuracy: 0.5926 - val_loss: 0.6345 - val_accuracy: 0.6792\n"
     ]
    }
   ],
   "source": [
    "model_mlp = Sequential([\n",
    "        Flatten(input_shape = (64, 64, 3)),\n",
    "        Dense(128, activation = 'relu'),\n",
    "        Dense(64, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "model_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_mlp = model_mlp.fit(train_generator, validation_data = validation_generator, epochs=100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(model_mlp)\n",
    "model_names.append(\"Multi Layer Perceptron\")\n",
    "histories.append(history_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 0.8731 - accuracy: 0.4954 - val_loss: 0.6985 - val_accuracy: 0.4151\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 0.6781 - accuracy: 0.5741 - val_loss: 0.6637 - val_accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 0.6611 - accuracy: 0.5926 - val_loss: 0.6532 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.6431 - accuracy: 0.5926 - val_loss: 0.6477 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 0.6289 - accuracy: 0.5926 - val_loss: 0.6193 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.6224 - accuracy: 0.6019 - val_loss: 0.6185 - val_accuracy: 0.6981\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.5885 - accuracy: 0.7083 - val_loss: 0.5981 - val_accuracy: 0.6981\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 0.5812 - accuracy: 0.7176 - val_loss: 0.5654 - val_accuracy: 0.7170\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.5853 - accuracy: 0.6667 - val_loss: 0.6391 - val_accuracy: 0.6604\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 0.6107 - accuracy: 0.6528 - val_loss: 0.5718 - val_accuracy: 0.7547\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.5618 - accuracy: 0.7269 - val_loss: 0.6185 - val_accuracy: 0.6604\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.5994 - accuracy: 0.6713 - val_loss: 0.5517 - val_accuracy: 0.7170\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.5508 - accuracy: 0.7130 - val_loss: 0.4590 - val_accuracy: 0.8302\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.5532 - accuracy: 0.7037 - val_loss: 0.5429 - val_accuracy: 0.7736\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 52ms/step - loss: 0.4948 - accuracy: 0.7731 - val_loss: 0.6017 - val_accuracy: 0.6792\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.5321 - accuracy: 0.7500 - val_loss: 0.5388 - val_accuracy: 0.7736\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.5054 - accuracy: 0.7593 - val_loss: 0.5579 - val_accuracy: 0.6792\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.5289 - accuracy: 0.7130 - val_loss: 0.5378 - val_accuracy: 0.7170\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.5305 - accuracy: 0.7824 - val_loss: 0.5277 - val_accuracy: 0.7547\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.4875 - accuracy: 0.7454 - val_loss: 0.4498 - val_accuracy: 0.8113\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.4833 - accuracy: 0.7917 - val_loss: 0.5844 - val_accuracy: 0.7358\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.5270 - accuracy: 0.7361 - val_loss: 0.4694 - val_accuracy: 0.8491\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.5298 - accuracy: 0.8102 - val_loss: 0.4618 - val_accuracy: 0.8302\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 0.5020 - accuracy: 0.7361 - val_loss: 0.4120 - val_accuracy: 0.8868\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 0.4418 - accuracy: 0.7778 - val_loss: 0.4737 - val_accuracy: 0.8302\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.4089 - accuracy: 0.8009 - val_loss: 0.4782 - val_accuracy: 0.7358\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.4773 - accuracy: 0.7731 - val_loss: 0.4662 - val_accuracy: 0.7925\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.4225 - accuracy: 0.8102 - val_loss: 0.4397 - val_accuracy: 0.8302\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 0.4148 - accuracy: 0.8102 - val_loss: 0.4696 - val_accuracy: 0.8113\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.3847 - accuracy: 0.8056 - val_loss: 0.3898 - val_accuracy: 0.8679\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 0.3501 - accuracy: 0.8611 - val_loss: 0.4588 - val_accuracy: 0.7547\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.4157 - accuracy: 0.7778 - val_loss: 0.3716 - val_accuracy: 0.8302\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.3525 - accuracy: 0.8333 - val_loss: 0.3881 - val_accuracy: 0.8302\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.3979 - accuracy: 0.8287 - val_loss: 0.4141 - val_accuracy: 0.8113\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 0.3581 - accuracy: 0.8426 - val_loss: 0.3898 - val_accuracy: 0.8302\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.4190 - accuracy: 0.7778 - val_loss: 0.3503 - val_accuracy: 0.8113\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.3706 - accuracy: 0.8241 - val_loss: 0.4217 - val_accuracy: 0.8113\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.3568 - accuracy: 0.8565 - val_loss: 0.4366 - val_accuracy: 0.8113\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.3935 - accuracy: 0.8287 - val_loss: 0.3985 - val_accuracy: 0.8302\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.3629 - accuracy: 0.8333 - val_loss: 0.3641 - val_accuracy: 0.8491\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.3359 - accuracy: 0.8657 - val_loss: 0.3838 - val_accuracy: 0.7736\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 0.3826 - accuracy: 0.8380 - val_loss: 0.4438 - val_accuracy: 0.7547\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.3438 - accuracy: 0.8380 - val_loss: 0.4264 - val_accuracy: 0.8302\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.3468 - accuracy: 0.8333 - val_loss: 0.4580 - val_accuracy: 0.8113\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.3298 - accuracy: 0.8750 - val_loss: 0.4211 - val_accuracy: 0.8679\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.3083 - accuracy: 0.8704 - val_loss: 0.3675 - val_accuracy: 0.8113\n"
     ]
    }
   ],
   "source": [
    "lenet_model = Sequential([\n",
    "        Conv2D(6, (5, 5), activation = 'relu', padding = 'same', input_shape = (64, 64, 3)),\n",
    "        MaxPooling2D(pool_size = (2, 2)),\n",
    "        Conv2D(16, (5, 5), activation = 'relu'),\n",
    "        MaxPooling2D(pool_size = (2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(120, activation = 'relu'),\n",
    "        Dense(84, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "lenet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "lenet_history = lenet_model.fit(train_generator, validation_data = validation_generator, epochs = 100, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(lenet_model)\n",
    "model_names.append(\"LeNet - 5\")\n",
    "histories.append(lenet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 6s 572ms/step - loss: 4.5614 - accuracy: 0.5139 - val_loss: 0.7086 - val_accuracy: 0.3962\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.6995 - accuracy: 0.4074 - val_loss: 0.6940 - val_accuracy: 0.3962\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.6924 - accuracy: 0.5463 - val_loss: 0.6891 - val_accuracy: 0.6038\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.6878 - accuracy: 0.5926 - val_loss: 0.6835 - val_accuracy: 0.6038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.6820 - accuracy: 0.5926 - val_loss: 0.6749 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.6758 - accuracy: 0.5926 - val_loss: 0.6492 - val_accuracy: 0.6038\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.6452 - accuracy: 0.5926 - val_loss: 0.6275 - val_accuracy: 0.6038\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.5767 - accuracy: 0.5926 - val_loss: 0.5055 - val_accuracy: 0.6038\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5657 - accuracy: 0.5926 - val_loss: 0.4879 - val_accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.5367 - accuracy: 0.6111 - val_loss: 0.4807 - val_accuracy: 0.7170\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5896 - accuracy: 0.6944 - val_loss: 0.5592 - val_accuracy: 0.6792\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5658 - accuracy: 0.6250 - val_loss: 0.4866 - val_accuracy: 0.6038\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.5140 - accuracy: 0.6528 - val_loss: 0.4690 - val_accuracy: 0.7170\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.4874 - accuracy: 0.7083 - val_loss: 0.5469 - val_accuracy: 0.6226\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.4841 - accuracy: 0.7176 - val_loss: 0.4942 - val_accuracy: 0.6792\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5018 - accuracy: 0.7083 - val_loss: 0.4791 - val_accuracy: 0.6981\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.4679 - accuracy: 0.7222 - val_loss: 0.4993 - val_accuracy: 0.6792\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.4606 - accuracy: 0.7269 - val_loss: 0.4848 - val_accuracy: 0.6981\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.4779 - accuracy: 0.7083 - val_loss: 0.4969 - val_accuracy: 0.6792\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.4607 - accuracy: 0.7269 - val_loss: 0.4790 - val_accuracy: 0.6981\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.4688 - accuracy: 0.7269 - val_loss: 0.4948 - val_accuracy: 0.6792\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.4968 - accuracy: 0.7130 - val_loss: 0.4658 - val_accuracy: 0.7170\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.4839 - accuracy: 0.7083 - val_loss: 0.4995 - val_accuracy: 0.6792\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.4732 - accuracy: 0.7130 - val_loss: 0.4945 - val_accuracy: 0.6792\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.4553 - accuracy: 0.7361 - val_loss: 0.4780 - val_accuracy: 0.6981\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.4551 - accuracy: 0.7269 - val_loss: 0.4781 - val_accuracy: 0.6981\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.4685 - accuracy: 0.7176 - val_loss: 0.4972 - val_accuracy: 0.6792\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.4781 - accuracy: 0.7083 - val_loss: 0.5106 - val_accuracy: 0.6604\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.4700 - accuracy: 0.7130 - val_loss: 0.4613 - val_accuracy: 0.7170\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.4539 - accuracy: 0.7269 - val_loss: 0.4537 - val_accuracy: 0.7358\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.5349 - accuracy: 0.7222 - val_loss: 0.6868 - val_accuracy: 0.5094\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.6333 - accuracy: 0.6574 - val_loss: 0.4641 - val_accuracy: 0.7170\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.4686 - accuracy: 0.7176 - val_loss: 0.4685 - val_accuracy: 0.7170\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.4844 - accuracy: 0.7269 - val_loss: 0.4939 - val_accuracy: 0.6792\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.4516 - accuracy: 0.7361 - val_loss: 0.4609 - val_accuracy: 0.7170\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.4624 - accuracy: 0.7269 - val_loss: 0.4796 - val_accuracy: 0.6981\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.4628 - accuracy: 0.7269 - val_loss: 0.4946 - val_accuracy: 0.6792\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.4509 - accuracy: 0.7361 - val_loss: 0.4801 - val_accuracy: 0.6981\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.4703 - accuracy: 0.7269 - val_loss: 0.4621 - val_accuracy: 0.7170\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.4601 - accuracy: 0.7315 - val_loss: 0.5063 - val_accuracy: 0.6792\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = Sequential([\n",
    "        Conv2D(96, (11, 11), activation = 'relu', strides = (4, 4), input_shape = (224, 224, 3)),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Conv2D(256, (5, 5), activation = 'relu', padding = 'same'),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Conv2D(384, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(384, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPooling2D(pool_size = (3, 3), strides = (2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "alexnet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "alexnet_history = alexnet_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(alexnet_model)\n",
    "model_names.append(\"AlexNet\")\n",
    "histories.append(alexnet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 (Without Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 10) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m vgg_16_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m vgg16_history \u001b[38;5;241m=\u001b[39m \u001b[43mvgg_16_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator_224\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator_224\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileosn_604y.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 10) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "# Load VGG16 model\n",
    "base_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Build model\n",
    "vgg_16_model = Sequential([\n",
    "    base_vgg16,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_16_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg16_history = vgg_16_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(vgg_16_model)\n",
    "model_names.append(\"VGG16\")\n",
    "histories.append(vgg16_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 (Without Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Build model\n",
    "vgg_19_model = Sequential([\n",
    "    base_vgg19,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "vgg_19_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg19_history = vgg_19_model.fit(train_generator_224, validation_data = validation_generator_224, epochs = 100, \n",
    "                                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(vgg_19_model)\n",
    "model_names.append(\"VGG19\")\n",
    "histories.append(vgg19_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm1S5n-jo9PU"
   },
   "source": [
    "#### Evaluating the neural netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model and store results\n",
    "for i, (model, model_name, history) in enumerate(zip(models, model_names, histories)):\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    metrics = evaluate_model(model, validation_generator)\n",
    "    \n",
    "    # Print metrics for comparison\n",
    "    print(f\"Metrics for {model_name}:\")\n",
    "    print(f\"Loss: {metrics['loss']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics['classification_report'])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(metrics['confusion_matrix'], validation_generator.class_indices.keys(), model_name)\n",
    "\n",
    "    # Plot metrics if you have a history object\n",
    "    plot_metrics(history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
